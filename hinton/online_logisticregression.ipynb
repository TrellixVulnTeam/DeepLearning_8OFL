{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-212ce63baeeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDictReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'1'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Label'\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# can't let the model peek the answer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Label'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "           DO WHAT THE FUCK YOU WANT TO PUBLIC LICENSE\n",
    "                   Version 2, December 2004\n",
    "\n",
    "Copyright (C) 2004 Sam Hocevar <sam@hocevar.net>\n",
    "\n",
    "Everyone is permitted to copy and distribute verbatim or modified\n",
    "copies of this license document, and changing it is allowed as long\n",
    "as the name is changed.\n",
    "\n",
    "           DO WHAT THE FUCK YOU WANT TO PUBLIC LICENSE\n",
    "  TERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION\n",
    "\n",
    " 0. You just DO WHAT THE FUCK YOU WANT TO.\n",
    "'''\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "from csv import DictReader\n",
    "from math import exp, log, sqrt\n",
    "\n",
    "\n",
    "# parameters #################################################################\n",
    "\n",
    "train = 'train.tiny.csv'  # path to training file\n",
    "test = 'test.tiny.csv'  # path to testing file\n",
    "\n",
    "D = 2 ** 20   # number of weights use for learning\n",
    "alpha = .1    # learning rate for sgd optimization\n",
    "\n",
    "\n",
    "# function definitions #######################################################\n",
    "\n",
    "# A. Bounded logloss\n",
    "# INPUT:\n",
    "#     p: our prediction\n",
    "#     y: real answer\n",
    "# OUTPUT\n",
    "#     logarithmic loss of p given y\n",
    "def logloss(p, y):\n",
    "    p = max(min(p, 1. - 10e-12), 10e-12)\n",
    "    return -log(p) if y == 1. else -log(1. - p)\n",
    "\n",
    "\n",
    "# B. Apply hash trick of the original csv row\n",
    "# for simplicity, we treat both integer and categorical features as categorical\n",
    "# INPUT:\n",
    "#     csv_row: a csv dictionary, ex: {'Lable': '1', 'I1': '357', 'I2': '', ...}\n",
    "#     D: the max index that we can hash to\n",
    "# OUTPUT:\n",
    "#     x: a list of indices that its value is 1\n",
    "def get_x(csv_row, D):\n",
    "    x = [0]  # 0 is the index of the bias term\n",
    "    for key, value in csv_row.items():\n",
    "        index = int(value + key[1:], 16) % D  # weakest hash ever ;)\n",
    "        x.append(index)\n",
    "    return x  # x contains indices of features that have a value of 1\n",
    "\n",
    "\n",
    "# C. Get probability estimation on x\n",
    "# INPUT:\n",
    "#     x: features\n",
    "#     w: weights\n",
    "# OUTPUT:\n",
    "#     probability of p(y = 1 | x; w)\n",
    "def get_p(x, w):\n",
    "    wTx = 0.\n",
    "    for i in x:  # do wTx\n",
    "        wTx += w[i] * 1.  # w[i] * x[i], but if i in x we got x[i] = 1.\n",
    "    return 1. / (1. + exp(-max(min(wTx, 20.), -20.)))  # bounded sigmoid\n",
    "\n",
    "\n",
    "# D. Update given model\n",
    "# INPUT:\n",
    "#     w: weights\n",
    "#     n: a counter that counts the number of times we encounter a feature\n",
    "#        this is used for adaptive learning rate\n",
    "#     x: feature\n",
    "#     p: prediction of our model\n",
    "#     y: answer\n",
    "# OUTPUT:\n",
    "#     w: updated model\n",
    "#     n: updated count\n",
    "def update_w(w, n, x, p, y):\n",
    "    for i in x:\n",
    "        # alpha / (sqrt(n) + 1) is the adaptive learning rate heuristic\n",
    "        # (p - y) * x[i] is the current gradient\n",
    "        # note that in our case, if i in x then x[i] = 1\n",
    "        w[i] -= (p - y) * alpha / (sqrt(n[i]) + 1.)\n",
    "        n[i] += 1.\n",
    "\n",
    "    return w, n\n",
    "\n",
    "\n",
    "# training and testing #######################################################\n",
    "\n",
    "# initialize our model\n",
    "w = [0.] * D  # weights\n",
    "n = [0.] * D  # number of times we've encountered a feature\n",
    "\n",
    "# start training a logistic regression model using on pass sgd\n",
    "loss = 0.\n",
    "for t, row in enumerate(DictReader(open(train))):\n",
    "    y = 1. if row['Label'] == '1' else 0.\n",
    "\n",
    "    del row['Label']  # can't let the model peek the answer\n",
    "    del row['Id']  # we don't need the Id\n",
    "\n",
    "    # main training procedure\n",
    "    # step 1, get the hashed features\n",
    "    x = get_x(row, D)\n",
    "\n",
    "    # step 2, get prediction\n",
    "    p = get_p(x, w)\n",
    "\n",
    "    # for progress validation, useless for learning our model\n",
    "    loss += logloss(p, y)\n",
    "    if t % 1000000 == 0 and t > 1:\n",
    "        print('%s\\tencountered: %d\\tcurrent logloss: %f' % (\n",
    "            datetime.now(), t, loss/t))\n",
    "\n",
    "    # step 3, update model with answer\n",
    "    w, n = update_w(w, n, x, p, y)\n",
    "\n",
    "# testing (build kaggle's submission file)\n",
    "with open('submission1234.csv', 'w') as submission:\n",
    "    submission.write('Id,Predicted\\n')\n",
    "    for t, row in enumerate(DictReader(open(test))):\n",
    "        Id = row['Id']\n",
    "        del row['Id']\n",
    "        x = get_x(row, D)\n",
    "        p = get_p(x, w)\n",
    "        submission.write('%s,%f\\n' % (Id, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
