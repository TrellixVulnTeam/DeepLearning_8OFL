{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Numpy shapes</h4>\n",
    "<p>Reformatting for one hot encoding</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_np shape: (5,)\n",
      "test1dim shape: (5, 1)\n",
      "foo shape: (5, 1)\n",
      "foo_newaxis shape: (5, 1)\n",
      "orig shape: (5,)\n",
      "minus_one shape: [0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from numpy import newaxis\n",
    "\n",
    "#an np.array created from a list of 5 itesms in a python list has shape (5,). There is no second dimension\n",
    "#The (5,) shape is the shape we need for 1 hot encoding\n",
    "list_np = np.array([0, 0, 1, 0, 0])\n",
    "print (\"list_np shape:\", list_np.shape)\n",
    "\n",
    "#a numpy array with shape 5,1 is created with the notation for a 2dim array. \n",
    "test1dim = np.array([[0], [0], [1], [0], [0]])\n",
    "print(\"test1dim shape:\", test1dim.shape)\n",
    "\n",
    "\n",
    "# a common operation is to have to convert between (5,) and (5,1) or vice versa \n",
    "#to reshape a (5,) to (5,1) can use newaxis or -1 as the second index. \n",
    "foo = list_np[...,None]\n",
    "print(\"foo shape:\", foo.shape)\n",
    "# foo is a view on the numpy array and you have to do the assignment and work\n",
    "# with the symbol for the new view for code to work on the new dimensions\n",
    "#anohter way is to use newaxis. \n",
    "foo_newaxis = list_np[...,newaxis]\n",
    "print(\"foo_newaxis shape:\", foo_newaxis.shape)\n",
    "# \n",
    "#to go back to the original\n",
    "orig = foo_newaxis.reshape(foo_newaxis.shape[0],)\n",
    "print(\"orig shape:\", orig.shape)\n",
    "\n",
    "#\n",
    "# -1 reshape to convert from [[0],[0],[0],[1]] notation to [ 0 0 0 1]\n",
    "#\n",
    "minus_one = test1dim[...,-1]\n",
    "print(\"minus_one shape:\",minus_one)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "<h4>Tensorflow shapes</h4>\n",
    "<p>Reformatting for onehot and correlation with numpy shapes. Numpy and tensorflow shapes are not the same. \n",
    "Currently there is some sort of compatability but that is going to change in the future in some undetermined way. \n",
    "A tensorflow shape refers to the number of tensor dimensions vs. matrix dimensions.\n",
    "<p></p>\n",
    "A tensor is a multidimensional\n",
    "array with the number of indexes defined as the tensorflow rank. A matix rank is the number of independent columns. \n",
    "A tensor $X_a$ has a rank of 1, $X_ab$ a rank of 2\n",
    "$X_abc$ rank, $X_abcd$ a rank of 4 and so on. \n",
    "</p>\n",
    "\n",
    "<p></p>\n",
    "Tensorflow shapes are not immutable. Tensorflow shapes can be changed as the result of tensor operations. A tensor product\n",
    "of 2 tensors, one (mxn)*(n*p) will result in a new tensor shape of mxp. There are 2 tensor shapes, a static and dynamic\n",
    "shape. A static shape is set at runtime. There are cases such as a placeholder the full tensor dimensions are not determined\n",
    "until runtime. The runtime tensor shape is the dynamic tensor shape. \n",
    "<p></p>\n",
    "<h4>DNN From Udacity</h4>\n",
    "They define a DNN with a RELU activation. Everybody has a different definition of DNN. \n",
    "<h4>DNN From TF Estimator Source Code</h4>\n",
    "<p></p>\n",
    "<p></p>\n",
    "<h4>ConvNet</h4>\n",
    "Certain predefined functions have predefined tensor shapes for their input. \n",
    "Conv2D requires the input tensor to be a 4D tensor with shape = [batch_size, rows, cols, depth_in]\n",
    "and filter, a 4D tensor with shape =  [filter_rows, filter_cols, depth_in, depth_out]\n",
    "The output is a 4D tensor with shape = [batch_size, out_rows,\n",
    "  out_cols, depth_out], where out_rows and out_cols depend on the\n",
    "  value of the op's \"padding\" and \"strides\" attrs.\n",
    "<p></p>\n",
    "The formulas for output size are: \n",
    "\n",
    "<p></p>\n",
    "Vincent did a couple of lectures on this which have since been removed. \n",
    "<p></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
