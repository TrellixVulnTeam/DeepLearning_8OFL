{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h2> outline<h2>\n",
    "<h4> 3 independent concepts</h4> \n",
    "<li>multiclass classifiers softmax regression</li> \n",
    "<li>backprop/vanishing gradients</li>\n",
    "<li>how to set weights/gradient descent(full training set)/SGD(online)</li>\n",
    "<h4> linear/logistic regression</h4>\n",
    "<h4> softmax regression</h4>\n",
    "<h4> cross entropy and softmax</h4>\n",
    "<h4> backpropagation in NN</h4>\n",
    "<h4> vanishing gradient demo</h4>\n",
    "<h4> relu</h4>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](nn.png \"NN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This is a 2 layer network with a logistic in the output of the hidden layer and a LOGISTIC at the outpue node. Usually there is a linear FC layer here. There are K inputs, N hidden neurons and M outputs.  The hidden layer is a function of the output $y_i$. Let's add a change of variable to $u_i$ for the hidden logistic node and a change of variable to v for the output logistic unit $y_i$. \n",
    "\n",
    "${h}_i=f({u}_i)=f(\\sum_{k=1}^{K}w_{ki}x_{k}) = \\frac{1}{1+e^{-u_i}}$\n",
    "\n",
    "where we defined:\n",
    "    \n",
    "${u}_i = \\sum_{k=1}^{K}w_{ki}x_{k}$\n",
    "\n",
    "The output layer:\n",
    "\n",
    "${y}_i=f({v}_i) = f(\\sum_{k=1}^{K}w^{\\prime}_{ij}h_{k})$\n",
    "\n",
    "where $h_i$ is the output of the logistic unit. If there is additipnal processing such as whitening; this is preformed \n",
    "here and output as hk. We define v as:\n",
    "\n",
    "    \n",
    "${v}_i = \\sum_{k=1}^{K}w^{\\prime}_{ij}x_{k}= \\frac{1}{1+e^{-v_i}}$    \n",
    "    \n",
    "    \n",
    "Minimize the squared error between the training set output and actual:\n",
    "\n",
    "$E=\\frac{1}{2}\\sum_{n=1}^{K}({t}_n - {y}_n)^2 $\n",
    "\n",
    "$from \\; y=\\frac{1}{e^{-z}+1} \\;and\\; \\frac{dy}{dz}=y(1-y)$\n",
    "\n",
    "we can calculate $\\frac{dy_i}{dv_i}$\n",
    "\n",
    "$\\frac{dy}{dv} \\;=\\; y(1-y)$\n",
    "\n",
    "\n",
    "At the ouptut node y changes as a function of the weights and input to the hidden layer.\n",
    "There are 2 layers we have to work through; first from the output of the hidden layer with weights wij prime then \n",
    "to the input of the hidden layer with weights wki. \n",
    "\n",
    "\n",
    "$\\frac{\\partial E}{\\partial y} = \\sum_{n=1}^{M}  -({t}_n - {y}_n) $\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We want to determine the effect of changing weights on the output. There are 2 sets of weights, the weights after\n",
    "the hidden layer and the set of weights before the hidden layer. Changing the value of theseweights should narrow or widen\n",
    "the difference beween the training sample and output summed over all samples. We use the chain rule in 2 steps to first \n",
    "rewrite the dE/dy term in terms of the w prime weights then using the same logic the w set of weights</p>\n",
    "\n",
    "$\\frac{\\partial{E}}{\\partial {w^{\\prime}_{ij}}}=\\frac{\\partial E}{\\partial y_{j}} \\frac{dy}{dv_{j}} \\frac{\\partial v_j}{\\partial {w^{\\prime}_ij}}$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>substituting from above:</p>\n",
    "    \n",
    "$\\frac {\\partial E}{\\partial w^{\\prime}_{ij}} = -(t_n - y_n) \\cdot y_{j}(1-y_{j}) \\cdot h_{i}$    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>From the equation above we can see given an observed output from the NN we have an expression for the weights which\n",
    "depends on the layer before and the observed output value. This process of converting the output values to get the change\n",
    "in weights based on weight values and input of the previous stage is backpropagation and depends on the chain rule. To update\n",
    "the weights we add an additional term epsilon indicating the new weights are a small change to the desired output</p>\n",
    "\n",
    "\n",
    "$w^{\\prime updated}_{ki} = w^{\\prime old}_{ki}  -\\epsilon \\cdot (t_n - y_n) \\cdot y_{j}(1-y_{j}) \\cdot h_{i}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>the update rules for the next set of weights are backpropagated from this hidden layer stage to the input</p>\n",
    "\n",
    "$\\frac{\\partial E}{\\partial w_{ki}} =\\sum_{i=1}^{M}(\\frac{\\partial E}{\\partial y_i} \\cdot \\frac{\\partial y_i}{\\partial v_i} \\cdot \\frac{\\partial v_i}{\\partial h_i} )\\cdot \\frac{\\partial h_i}{\\partial u_i}\\frac{\\partial u_i}{\\partial w_{ki}}  $\n",
    "\n",
    "\n",
    "<p>The first part in parenthesis is what we just computed. The next 2 derivatives:</p>\n",
    "\n",
    "$\\frac{\\partial h_i}{\\partial u_i} = h_i \\cdot (1-h_i)$  where $h_i$ is the logistic\n",
    "\n",
    "$\\frac{\\partial u_i}{\\partial w_{ki} }  = x_i$\n",
    "\n",
    "$\\frac{\\partial E}{\\partial w_{ki}} = \\sum_{i=1}^{M}(t_i - y_i) \\cdot y_{i}(1-y_i) \\cdot\n",
    "    \n",
    "<p>The weight update becomes:</p> \n",
    "\n",
    "$w^{updated}_ki = w^{old}_ki - -\\epsilon \\cdot (t_n - y_n) \\cdot y_{j}(1-y_{j}) \\cdot h_{i} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tf35]",
   "language": "python",
   "name": "conda-env-tf35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
