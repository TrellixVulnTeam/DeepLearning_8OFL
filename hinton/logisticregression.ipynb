{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "<h4>Logistic Regression</h4>\n",
    "Logistic  Regression is a special case for Multinomial Logistic Regression with the number of classes =2. \n",
    "sklearn and keras examples for reference. No fully working examples on web I could find. All non functioning snippets\n",
    "including the keras examples page. The hardest part to debug is getting the input data format correct. There are\n",
    "no useful error messages. \n",
    "<p>Notes to self: if I am reading this I am confused. The easiest dataset to start with is IRIS and the easiest\n",
    "    impelementation to run is sklearn . IRIS because\n",
    "    there are 4 columns of attributes and the dataset is clean and verivied a billion times by others and\n",
    "    you can view the entire dataset. No nulls, zeros, large numbers, no junk, bad values.. more ranting here..\n",
    "    And sklearn cause it is old, runs in ipython, has lots of cool people watching over it who are not trying\n",
    "    to start comapanies. \n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4) (150, 4)\n",
      "(150,) (150,)\n",
      "<class 'numpy.ndarray'>\n",
      "(100, 4)\n",
      "(150, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.97999999999999998"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "iris_X = iris.data\n",
    "iris_y = iris.target\n",
    "\n",
    "y = iris.target\n",
    "X=iris.data[:, :4]\n",
    "\n",
    "print(X.shape,iris_X.shape)\n",
    "print(y.shape,iris_y.shape)\n",
    "print(type(X))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(iris_X.shape)\n",
    "logistic = linear_model.LogisticRegression(C=1e5)\n",
    "logistic.fit(X_train, y_train)\n",
    "pred = logistic.predict(X_test)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100 samples, validate on 50 samples\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 0s - loss: -0.3076 - val_loss: 0.0162\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 0s - loss: -0.3271 - val_loss: 0.0062\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 0s - loss: -0.3403 - val_loss: -0.0025\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 0s - loss: -0.3505 - val_loss: -0.0129\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 0s - loss: -0.3643 - val_loss: -0.0181\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 0s - loss: -0.3706 - val_loss: -0.0261\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 0s - loss: -0.3803 - val_loss: -0.0328\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 0s - loss: -0.3895 - val_loss: -0.0412\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 0s - loss: -0.3983 - val_loss: -0.0468\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 0s - loss: -0.4057 - val_loss: -0.0534\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12fec0a90>"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Keras IRIS implementation. \n",
    "model = Sequential()\n",
    "model.add(Dense(1, activation='sigmoid', input_dim=X_train.shape[1]))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy')\n",
    "model.fit(X_train, y_train, nb_epoch=10, validation_data=(X_test, y_test))\n",
    "model.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Multinomial Logistic Classification</h4>\n",
    "For multiple classes, our logistic classifier uses\n",
    "<li>A linear model to calculate weights and bias</li>\n",
    "<li>The float number output of the linear model is called a score</li>\n",
    "<li>The score is input into a logistic/logit/softmax to output a probability between 0,1</li>\n",
    "<li>The score is input into a cross entropy with the one hot encoded labels of the training set to calculate\n",
    "the training loss</li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.36787944  0.27067057  0.14936121]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "scores = [[1.0,2.0,3.0]]\n",
    "\n",
    "def softmax(scores):\n",
    "    '''\n",
    "    input: 2d array\n",
    "    this code is vectorized input an array into np.exp and it returns exp for each element\n",
    "    '''\n",
    "    sum = 0.\n",
    "    for x in scores:\n",
    "        sum += np.exp(x)\n",
    "    for x in scores:\n",
    "        results = np.divide(x,sum)\n",
    "    return results\n",
    "\n",
    "print (softmax(scores))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "<h4>Cross Entropy</h4>\n",
    "<p></p>\n",
    "$D(S,L) = -\\sum L_i log(S_i)$ \n",
    "<p></p>\n",
    "where $L_i$ is the one hot vector and $S_i$ is the probability distribution. This is not symmetrical!!!!!! You can \n",
    "reason what the order is in that it does not make sense to take a log of 0 which is what is in the one hot vectors. \n",
    "<p></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.36787944  0.27067057  0.14936121]\n"
     ]
    }
   ],
   "source": [
    "def cross_entropy(x,y):\n",
    "    '''\n",
    "    input x: probability\n",
    "    y: one hot labels\n",
    "    output: cross entropy score\n",
    "    '''\n",
    "    \n",
    "scores=[[1.0,2.0,3.0]]\n",
    "x = softmax(scores)\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the pairs must be equal else you get tuple errors\n",
      "X.shape,iris_X.shape (150, 4) (150, 4)\n",
      "y.shape,iris_y.shape (150,) (150,)\n",
      "the following first dimensions must be equal\n",
      "X,y shape (150, 4) (150,)\n",
      "X,y type <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "first row X,y: [ 5.1  3.5  1.4  0.2] 0\n",
      "(50, 4) (50,)\n",
      "\r",
      "32/50 [==================>...........] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.97999999999999998"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "iris_X = iris.data\n",
    "iris_y = iris.target\n",
    "\n",
    "y = iris.target\n",
    "X=iris.data[:, :4]\n",
    "\n",
    "print(\"the pairs must be equal else you get tuple errors\")\n",
    "print(\"X.shape,iris_X.shape\",X.shape,iris_X.shape)\n",
    "print(\"y.shape,iris_y.shape\",y.shape,iris_y.shape)\n",
    "print(\"the following first dimensions must be equal\")\n",
    "print(\"X,y shape\",X.shape,y.shape)\n",
    "print(\"X,y type\",type(X),type(y))\n",
    "\n",
    "print(\"first row X,y:\",X[0],y[0])\n",
    "\n",
    "assert(X_train.shape[0]==y_train.shape[0])\n",
    "print(X_test.shape,y_test.shape)\n",
    "assert(X_test.shape[0]==y_test.shape[0])\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "logistic = linear_model.LogisticRegression(C=1e5)\n",
    "logistic.fit(X_train, y_train)\n",
    "score = model.evaluate(X_test, y_test)\n",
    "pred = logistic.predict(X_test)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100 samples, validate on 50 samples\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 0s - loss: -0.8996 - val_loss: -0.6267\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 0s - loss: -0.9223 - val_loss: -0.6399\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 0s - loss: -0.9388 - val_loss: -0.6464\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 0s - loss: -0.9472 - val_loss: -0.6561\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 0s - loss: -0.9596 - val_loss: -0.6634\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 0s - loss: -0.9686 - val_loss: -0.6694\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 0s - loss: -0.9757 - val_loss: -0.6773\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 0s - loss: -0.9867 - val_loss: -0.6823\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 0s - loss: -0.9914 - val_loss: -0.6876\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 0s - loss: -0.9968 - val_loss: -0.6933\n",
      "score: -0.6932923913\n",
      "acc: 0.3\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1, activation='sigmoid', input_dim=X_train.shape[1]))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy')\n",
    "model.fit(X_train, y_train, nb_epoch=10, validation_data=(X_test, y_test))\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"score:\",score)\n",
    "preds = model.predict(X_test)\n",
    "estiy = (preds>0.5)\n",
    "acc = np.mean(estiy[:,0] == y_test)\n",
    "print ('acc:', acc)\n",
    "#print (preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import keras as K\n",
    "\n",
    "df = pd.read_csv('binary.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class balance check\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "admit\n",
       "0    273\n",
       "1    127\n",
       "dtype: int64"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"class balance check\")\n",
    "counts = df.groupby('admit').size(); counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(268, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(268, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(132, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(132, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>520</td>\n",
       "      <td>3.51</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>620</td>\n",
       "      <td>3.23</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>340</td>\n",
       "      <td>2.92</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>600</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>720</td>\n",
       "      <td>3.42</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     gre   gpa  rank\n",
       "258  520  3.51     2\n",
       "177  620  3.23     3\n",
       "119  340  2.92     3\n",
       "194  600  3.47     2\n",
       "229  720  3.42     2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     admit\n",
       "258      0\n",
       "177      1\n",
       "119      0\n",
       "194      1\n",
       "229      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>580</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>660</td>\n",
       "      <td>3.94</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>740</td>\n",
       "      <td>3.34</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>580</td>\n",
       "      <td>2.93</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     gre   gpa  rank\n",
       "209  580  3.50     2\n",
       "280  660  3.94     2\n",
       "33   800  4.00     3\n",
       "210  740  3.34     4\n",
       "93   580  2.93     2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     admit\n",
       "209      0\n",
       "280      0\n",
       "33       1\n",
       "210      0\n",
       "93       0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import display\n",
    "import numpy\n",
    "\n",
    "#pandas dataframes, get columns by [['column name']] and get numpy array by values\n",
    "\n",
    "display(df.values.shape)\n",
    "display(type(df.values))\n",
    "\n",
    "print(\"------------------------\")\n",
    "≈display(X_train.shape,y_train.shape)\n",
    "assert(X_train.shape[0]==y_train.shape[0])\n",
    "display(X_test.shape,y_test.shape)\n",
    "assert(X_test.shape[0]==y_test.shape[0])\n",
    "\n",
    "print('-------------------------')\n",
    "\n",
    "display(X_train.head())\n",
    "display(y_train.head())\n",
    "display(X_test.head())\n",
    "display(y_test.head())\n",
    "\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values\n",
    "\n",
    "display(type(X_test),type(y_test))\n",
    "assert(type(X_train)==numpy.ndarray)\n",
    "assert(type(X_test)==numpy.ndarray)\n",
    "assert(type(y_train)==numpy.ndarray)\n",
    "assert(type(y_test)==numpy.ndarray)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train[0], y_train[0] [ 5.7  2.9  4.2  1.3] 1\n",
      "X_test[0], y_test[0] [ 6.1  2.8  4.7  1.2] 1\n",
      "(100,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 100 into shape (268,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-305-75edbe38d128>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"X_test[0], y_test[0]\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m268\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#print(y_train.shape,y_test.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 100 into shape (268,)"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('binary.csv')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "print(\"X_train[0], y_train[0]\",X_train[0], y_train[0])\n",
    "print(\"X_test[0], y_test[0]\",X_test[0], y_test[0])\n",
    "print(y_train.shape)\n",
    "y_train = y_train.reshape(268,)\n",
    "y_test= y_test.reshape(y_test.shape[0])\n",
    "#print(y_train.shape,y_test.shape)\n",
    "logistic = linear_model.LogisticRegression(C=1e5)\n",
    "logistic.fit(X_train, y_train)\n",
    "score = model.evaluate([[4.5] ,[6.0], [5.4 ], [5.5]], 0,verbose=2)\n",
    "#pred = logistic.predict(X_test)\n",
    "#accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
