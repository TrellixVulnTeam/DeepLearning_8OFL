{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "<h4>Logistic Regression</h4>\n",
    "Logistic  Regression is a special case for Multinomial Logistic Regression with the number of classes =2. \n",
    "sklearn and keras examples for reference. No fully working examples on web I could find. All non functioning snippets\n",
    "including the keras examples page. The hardest part to debug is getting the input data format correct. There are\n",
    "no useful error messages. \n",
    "<p>Notes to self: if I am reading this I am confused. The easiest dataset to start with is IRIS and the easiest\n",
    "    impelementation to run is sklearn . IRIS because\n",
    "    there are 4 columns of attributes and the dataset is clean and verivied a billion times by others and\n",
    "    you can view the entire dataset. No nulls, zeros, large numbers, no junk, bad values.. more ranting here..\n",
    "    And sklearn cause it is old, runs in ipython, has lots of cool people watching over it who are not trying\n",
    "    to start comapanies. \n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the pairs must be equal else you get tuple errors\n",
      "X.shape,iris_X.shape (150, 4) (150, 4)\n",
      "y.shape,iris_y.shape (150,) (150,)\n",
      "the following first dimensions must be equal\n",
      "X,y shape (150, 4) (150,)\n",
      "X,y type <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "first row X,y: [ 5.1  3.5  1.4  0.2] 0\n",
      "(80,) (80,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.97999999999999998"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "iris_X = iris.data\n",
    "iris_y = iris.target\n",
    "\n",
    "y = iris.target\n",
    "X=iris.data[:, :4]\n",
    "\n",
    "print(\"the pairs must be equal else you get tuple errors\")\n",
    "print(\"X.shape,iris_X.shape\",X.shape,iris_X.shape)\n",
    "print(\"y.shape,iris_y.shape\",y.shape,iris_y.shape)\n",
    "print(\"the following first dimensions must be equal\")\n",
    "print(\"X,y shape\",X.shape,y.shape)\n",
    "print(\"X,y type\",type(X),type(y))\n",
    "\n",
    "print(\"first row X,y:\",X[0],y[0])\n",
    "\n",
    "assert(X_train.shape[0]==y_train.shape[0])\n",
    "print(X_test.shape,y_test.shape)\n",
    "assert(X_test.shape[0]==y_test.shape[0])\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "logistic = linear_model.LogisticRegression(C=1e5)\n",
    "logistic.fit(X_train, y_train)\n",
    "#score = model.evaluate(X_test, y_test)\n",
    "pred = logistic.predict(X_test)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100 samples, validate on 50 samples\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 0s - loss: 7.4265 - val_loss: 6.8856\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 0s - loss: 7.2957 - val_loss: 6.8019\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 0s - loss: 7.2074 - val_loss: 6.7136\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 0s - loss: 7.1177 - val_loss: 6.6587\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 0s - loss: 7.0574 - val_loss: 6.5903\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 0s - loss: 6.9846 - val_loss: 6.5397\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 0s - loss: 6.9295 - val_loss: 6.4858\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 0s - loss: 6.8704 - val_loss: 6.4224\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 0s - loss: 6.8026 - val_loss: 6.3648\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 0s - loss: 6.7390 - val_loss: 6.2914\n",
      "score: 6.29142120361\n",
      "acc: 0.38\n"
     ]
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "\n",
    "iris_X = iris.data\n",
    "iris_y = iris.target\n",
    "\n",
    "y = iris.target\n",
    "X=iris.data[:, :4]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1, activation='sigmoid', input_dim=X_train.shape[1]))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy')\n",
    "model.fit(X_train, y_train, nb_epoch=10, validation_data=(X_test, y_test))\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"score:\",score)\n",
    "preds = model.predict(X_test)\n",
    "estiy = (preds>0.5)\n",
    "acc = np.mean(estiy[:,0] == y_test)\n",
    "print ('acc:', acc)\n",
    "#print (preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "<h4></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import keras as K\n",
    "\n",
    "df = pd.read_csv('binary.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class balance check\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "admit\n",
       "0    273\n",
       "1    127\n",
       "dtype: int64"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"class balance check\")\n",
    "counts = df.groupby('admit').size(); counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(268, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(268, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(132, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(132, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>520</td>\n",
       "      <td>3.51</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>620</td>\n",
       "      <td>3.23</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>340</td>\n",
       "      <td>2.92</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>600</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>720</td>\n",
       "      <td>3.42</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     gre   gpa  rank\n",
       "258  520  3.51     2\n",
       "177  620  3.23     3\n",
       "119  340  2.92     3\n",
       "194  600  3.47     2\n",
       "229  720  3.42     2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     admit\n",
       "258      0\n",
       "177      1\n",
       "119      0\n",
       "194      1\n",
       "229      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>580</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>660</td>\n",
       "      <td>3.94</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>740</td>\n",
       "      <td>3.34</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>580</td>\n",
       "      <td>2.93</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     gre   gpa  rank\n",
       "209  580  3.50     2\n",
       "280  660  3.94     2\n",
       "33   800  4.00     3\n",
       "210  740  3.34     4\n",
       "93   580  2.93     2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     admit\n",
       "209      0\n",
       "280      0\n",
       "33       1\n",
       "210      0\n",
       "93       0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import display\n",
    "import numpy\n",
    "\n",
    "#pandas dataframes, get columns by [['column name']] and get numpy array by values\n",
    "\n",
    "display(df.values.shape)\n",
    "display(type(df.values))\n",
    "\n",
    "print(\"------------------------\")\n",
    "display(X_train.shape,y_train.shape)\n",
    "assert(X_train.shape[0]==y_train.shape[0])\n",
    "display(X_test.shape,y_test.shape)\n",
    "assert(X_test.shape[0]==y_test.shape[0])\n",
    "\n",
    "print('-------------------------')\n",
    "\n",
    "display(X_train.head())\n",
    "display(y_train.head())\n",
    "display(X_test.head())\n",
    "display(y_test.head())\n",
    "\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values\n",
    "\n",
    "display(type(X_test),type(y_test))\n",
    "assert(type(X_train)==numpy.ndarray)\n",
    "assert(type(X_test)==numpy.ndarray)\n",
    "assert(type(y_train)==numpy.ndarray)\n",
    "assert(type(y_test)==numpy.ndarray)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(320, 1) (80, 1) (320, 1) (80, 1)\n",
      "---------frist row-------------\n",
      "X_train[0], y_train[0] [640] [1]\n",
      "X_test[0], y_test[0] [580] [0]\n",
      "---------frist row-------------\n",
      "0.6625\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(320, 2) (80, 2) (320, 1) (80, 1)\n",
      "---------frist row-------------\n",
      "X_train[0], y_train[0] [ 640.      3.19] [1]\n",
      "X_test[0], y_test[0] [ 580.     3.5] [0]\n",
      "---------frist row-------------\n",
      "0.6875\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(320, 3) (80, 3) (320, 1) (80, 1)\n",
      "---------frist row-------------\n",
      "X_train[0], y_train[0] [ 640.      3.19    4.  ] [1]\n",
      "X_test[0], y_test[0] [ 580.     3.5    2. ] [0]\n",
      "---------frist row-------------\n",
      "0.675\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('binary.csv')\n",
    "y = df[['admit']]\n",
    "X = df[['gre']]\n",
    "y=y.values\n",
    "X=X.values\n",
    "\n",
    "\n",
    "def run_model(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "    print(type(X_train),type(X_test),type(y_train),type(y_test))\n",
    "    print(X_train.shape,X_test.shape,y_train.shape,y_test.shape )\n",
    "\n",
    "    print ('---------frist row-------------')\n",
    "    print(\"X_train[0], y_train[0]\",X_train[0], y_train[0])\n",
    "    print(\"X_test[0], y_test[0]\",X_test[0], y_test[0])\n",
    "    print ('---------frist row-------------')\n",
    "\n",
    "    y_train = y_train.reshape(y_train.shape[0],)\n",
    "    y_test= y_test.reshape(y_test.shape[0])\n",
    "\n",
    "    logistic = linear_model.LogisticRegression(C=1e5)\n",
    "    logistic.fit(X_train, y_train)\n",
    "    pred = logistic.predict(X_test)\n",
    "    ac = accuracy_score(y_test, pred)\n",
    "    print (ac)\n",
    "\n",
    "run_model(X,y)\n",
    "df = pd.read_csv('binary.csv')\n",
    "X = df[['gre','gpa']]\n",
    "X=X.values\n",
    "run_model(X,y)\n",
    "X = df[['gre','gpa','rank']]\n",
    "X=X.values\n",
    "run_model(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 360 samples, validate on 40 samples\n",
      "Epoch 1/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 2/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 3/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 4/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 5/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 6/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 7/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 8/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 9/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 10/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 11/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 12/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 13/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 14/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 15/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 16/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 17/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 18/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 19/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 20/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 21/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 22/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 23/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 24/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 25/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 26/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 27/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 28/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 29/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 30/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 31/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 32/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 33/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 34/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 35/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 36/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 37/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 38/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 39/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 40/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 41/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 42/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 43/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 44/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 45/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 46/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 47/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 48/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 49/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 50/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 51/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 52/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 53/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 54/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 55/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 56/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 57/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 58/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 59/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 60/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 61/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 62/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 63/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 64/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 65/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 66/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 67/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 68/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 69/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 70/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 71/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 72/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 73/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 74/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 75/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 76/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 77/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 78/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 79/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 80/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 81/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 82/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 83/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 84/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 85/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 86/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 87/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 88/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 89/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 90/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 91/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 92/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 93/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 94/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 95/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 96/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 97/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 98/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 99/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "Epoch 100/100\n",
      "360/360 [==============================] - 0s - loss: 5.0593 - val_loss: 5.6413\n",
      "score: 5.64133338928\n",
      "acc: 0.65\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('binary.csv')\n",
    "y = df[['admit']]\n",
    "X = df[['gre','gpa','rank']]\n",
    "y=y.values\n",
    "X=X.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=42)\n",
    "   \n",
    "model = Sequential()\n",
    "model.add(Dense(1, activation='sigmoid', input_dim=X_train.shape[1]))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy')\n",
    "model.fit(X_train, y_train, nb_epoch=100, validation_data=(X_test, y_test))\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"score:\",score)\n",
    "preds = model.predict(X_test)\n",
    "estiy = (preds>0.5)\n",
    "acc = np.mean(estiy[:,0] == y_test)\n",
    "print ('acc:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Multinomial Logistic Classification</h4>\n",
    "For multiple classes, our logistic classifier uses\n",
    "<li>A linear model to calculate weights and bias</li>\n",
    "<li>The float number output of the linear model is called a score</li>\n",
    "<li>The score is input into a logistic/logit/softmax to output a probability between 0,1</li>\n",
    "<li>The score is input into a cross entropy with the one hot encoded labels of the training set to calculate\n",
    "the training loss</li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.36787944  0.27067057  0.14936121]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "scores = [[1.0,2.0,3.0]]\n",
    "\n",
    "def softmax(scores):\n",
    "    '''\n",
    "    input: 2d array\n",
    "    this code is vectorized input an array into np.exp and it returns exp for each element\n",
    "    '''\n",
    "    sum = 0.\n",
    "    for x in scores:\n",
    "        sum += np.exp(x)\n",
    "    for x in scores:\n",
    "        results = np.divide(x,sum)\n",
    "    return results\n",
    "\n",
    "print (softmax(scores))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "<h4>Cross Entropy</h4>\n",
    "<p></p>\n",
    "$D(S,L) = -\\sum L_i log(S_i)$ \n",
    "<p></p>\n",
    "where $L_i$ is the one hot vector and $S_i$ is the probability distribution. This is not symmetrical!!!!!! You can \n",
    "reason what the order is in that it does not make sense to take a log of 0 which is what is in the one hot vectors. \n",
    "<p></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.36787944  0.27067057  0.14936121]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.3025850929940455"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cross_entropy(prob,onehot):\n",
    "    '''\n",
    "    input x: probability\n",
    "    y: one hot labels\n",
    "    output: cross entropy score\n",
    "    '''\n",
    "    return -np.dot(onehot, np.log(prob))\n",
    "    \n",
    "scores=[[1.0,2.0,3.0]]\n",
    "x = softmax(scores)\n",
    "print(x)\n",
    "\n",
    "onehot=np.array([1, 0, 0, 0, 0])\n",
    "prob=np.array([0.1, 0.5, 0.1, 0.1, 0.2])\n",
    "\n",
    "cross_entropy(prob,onehot)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "(60000, 784) (60000,) (10000, 784) (10000,)\n",
      "(60000, 784) (60000,) (10000, 784) (10000,) (60000, 10) (10000, 10)\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "5s - loss: 0.2431 - val_loss: 0.1060\n",
      "Epoch 2/10\n",
      "5s - loss: 0.1021 - val_loss: 0.0845\n",
      "Epoch 3/10\n",
      "5s - loss: 0.0761 - val_loss: 0.0715\n",
      "Epoch 4/10\n",
      "5s - loss: 0.0605 - val_loss: 0.0779\n",
      "Epoch 5/10\n",
      "5s - loss: 0.0508 - val_loss: 0.0773\n",
      "Epoch 6/10\n",
      "5s - loss: 0.0430 - val_loss: 0.0942\n",
      "Epoch 7/10\n",
      "5s - loss: 0.0394 - val_loss: 0.0827\n",
      "Epoch 8/10\n",
      "5s - loss: 0.0354 - val_loss: 0.0769\n",
      "Epoch 9/10\n",
      "5s - loss: 0.0321 - val_loss: 0.0951\n",
      "Epoch 10/10\n",
      "5s - loss: 0.0286 - val_loss: 0.0841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dc/anaconda/envs/tf35/lib/python3.5/site-packages/keras/models.py:697: UserWarning: The \"show_accuracy\" argument is deprecated, instead you should pass the \"accuracy\" metric to the model at compile time:\n",
      "`model.compile(optimizer, loss, metrics=[\"accuracy\"])`\n",
      "  warnings.warn('The \"show_accuracy\" argument is deprecated, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.0841047629728\n"
     ]
    }
   ],
   "source": [
    "#multiclass on mnist\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "batch_size = 128\n",
    "nb_classes = 10\n",
    "nb_epoch = 10\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "print(X_train.shape, y_train.shape, X_test.shape,y_test.shape)\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "print(X_train.shape, y_train.shape, X_test.shape,y_test.shape)\n",
    "\n",
    "\n",
    "#Y_train = (y_train==1).astype(np.int32)\n",
    "#Y_test = (y_test==1).astype(np.int32)\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape,y_test.shape,Y_train.shape,Y_test.shape)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(784,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "rms = RMSprop()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=rms)\n",
    "model.fit(X_train, Y_train,\n",
    "          batch_size=batch_size, nb_epoch=nb_epoch,verbose=2,validation_data=(X_test, Y_test))\n",
    "score = model.evaluate(X_test, Y_test,show_accuracy=True, verbose=2)\n",
    "\n",
    "#model.predict(Y_test)\n",
    "print('score:', score)\n",
    "#print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 1, 28, 28) (60000,) (10000, 1, 28, 28) (10000,) (60000, 10) (10000, 10)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 2 required positional arguments: 'nb_row' and 'nb_col'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-370-f021656a6348>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 2 required positional arguments: 'nb_row' and 'nb_col'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    " \n",
    "# 6. Preprocess class labels\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)\n",
    " \n",
    "print(X_train.shape, y_train.shape, X_test.shape,y_test.shape,Y_train.shape,Y_test.shape)\n",
    "\n",
    "model = Sequential()\n",
    " \n",
    "one = model.add(Conv2D(32,kernel_size=(3, 3),strides=(1,1), activation='relu', input_shape=(1,28,28)))\n",
    "print(one.shape)\n",
    "model.add(Conv2D(32,kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    " \n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, \n",
    "          batch_size=32, nb_epoch=10, verbose=1)\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "<h4>Simplest Linear Model NN</h4>\n",
    "Does this belong here? Maybe as a comparison to multinomial logistic? Or should be in another section? \n",
    "\n",
    "Assume MNIST image input 28x28. \n",
    "<li>Linear stage multiply by weight W and add bias b</li>\n",
    "<li>26 possible classes output from hidden layer into softmax</li>\n",
    "<li>output softmax and input into CE with 1 hot vector</li>\n",
    "Number of parameters 28*28*10+10. The input to the weight matrix is 28x28 so the weight matrix is 28x28 and the bias is by 10\n",
    "and there are 10 classes so the weights are 10 deep. \n",
    "<p></p>\n",
    "In general if have N inputs to W thand K outputs you have (n+1)*k parameters to use. The advantages of linear models\n",
    "is numerical stability. Small inputs to a linear model result in small outputs. And the derivative of a linear model\n",
    "is constant. You can't get more stable than a constant. We accelerate the matrix multiply using the GPU.\n",
    "\n",
    "<p></p>\n",
    "The simplest nonlinear function is a RELU. The derivative of a relu looks like a step function. \n",
    "<img src=\"relu1.png\">\n",
    "<img src=\"relu2.png\">\n",
    "<p></p>\n",
    "The relu helps with matching nonlinearities. Add multiple relus between hidden layers. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
