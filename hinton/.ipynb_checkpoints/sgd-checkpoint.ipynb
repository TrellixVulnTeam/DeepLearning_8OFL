{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "For linear neuron we have a quadratic bowl. For a hidden layer neuron we have multiple bowls. \n",
    "add multi surface from vincent pascal\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"ngsgd1.png\">\n",
    "<img src=\"ngsgd2.png\">\n",
    "\n",
    "Source Andrew Ng lecture notes\n",
    "Gradient descent use all the training samples\n",
    "SGD/Online: use one training sample\n",
    "MiniBatch: use batch, typically 100, 10 or some number user picks\n",
    "\n",
    "One problem is the direction of the gradient or epsilon we are moving towards as we update teh weights\n",
    "1) are we converging or just bouncing around b/c the learning rate is too big\n",
    "<img src =\"sgd1.png\" >\n",
    "\n",
    "\n",
    "\n",
    "2) are we not converging bc the learning rate is too small and/or we are going in the wrong direction\n",
    "<img src =\"sgd2.png\" >\n",
    "Images from Hinton/Coursera lecture slides\n",
    "\n",
    "3) are we stuck in a local minima? Annealing, where we wait for a stable point, ie no change in error rate then add a perturbation\n",
    "or change the learning rate to make it leave the local minimia\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tf35]",
   "language": "python",
   "name": "conda-env-tf35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
