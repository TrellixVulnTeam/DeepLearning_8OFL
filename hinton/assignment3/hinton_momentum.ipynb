{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h6>Momentum vs. SGD for optimization</h6>\n",
    "<img src=\"mom1.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "there are 2 types of numpy zero arrays, a shape filled with 0 or a shape filled with null or no allocated memory. \n",
    "a = np.arange(0,-1).reshape(2,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h6>Numerical Stability for calculating exponent divided by sum of exponents</h6>\n",
    "https://stackoverflow.com/questions/10278004/how-to-order-this-computation-for-numerical-stability\n",
    "\n",
    "<p>Do not calculate np.exp(x) directly, subtract x_max first</p>\n",
    "<p>tmp = np.array([-10**10, 10**10])</p>\n",
    "<p>tmp_max = tmp.max()</p>\n",
    "<p>logD = np.log(np.sum(np.exp(tmp-tmp_max))) + tmp_max</p>\n",
    "<p>log_v = tmp - log_D</p>\n",
    "<p>v = np.exp(log_v)</p>\n",
    "<p>>>> v\n",
    "array([ 0.,  1.])</p>\n",
    "<p></p>\n",
    "\n",
    "$log\\sum_{k=1}^{training set}exp(tmp-tmp_{max}) + tmp_{max}$\n",
    "\n",
    "$=log\\sum_{k=1}^{training set} \\frac{exp(tmp)}{exp(tmp_{max})} + tmp_{max}$\n",
    "\n",
    "$= log\\frac{1}{exp(tmp_{max})} \\sum_{k=1}^{training set}exp(tmp) + tmp_{max}$ \n",
    "\n",
    "$= log[exp(-tmp_{max}) \\sum_{k=1}^{training set} exp(tmp)] + tmp_{max}$\n",
    "\n",
    "$= logexp(-tmp_{max}) + log\\sum_{k=1}^{training set}exp(tmp) + tmp_{max}$\n",
    "\n",
    "$= -tmp_{max} + log\\sum_{k=1}^{training set} exp(tmp) + tmp_{max}$\n",
    "\n",
    "<p>The above sould reduce to summation exp(tmp)</p>\n",
    "<p>Below for fraction of exp(tmp)/summation(exp(tmp))</p>\n",
    "<p>Combine log_v = tmp=log_D and v=exp(log_v)</p>\n",
    "$v=exp(tmp-logD) = \\frac{exp(tmp)}{log_D}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "Reference: http://cs231n.github.io/linear-classify/#softmax\n",
    "\n",
    "$\\frac{exp(x)}{\\sum_{k=1}^{K} exp(x)}$\n",
    "<p></p>\n",
    "\n",
    "$\\frac{C * exp(x)}{C*\\sum_{k=1}^{K}exp(x)}$\n",
    "\n",
    "$\\frac{exp(x + logC)}{\\sum_{k=1}^{K}exp(x+logC)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5.76612770e-04   1.56739601e-03   4.26062410e-03   1.15815771e-02\n",
      "   3.14819905e-02   8.55769227e-02   2.32622194e-01   6.32332683e-01]\n"
     ]
    }
   ],
   "source": [
    "# this is a numerical stable way to compute exp(x)\n",
    "\n",
    "import numpy as np\n",
    "tmp=[1,2,3,4,5,6,7,8]\n",
    "#tmp = np.array([-10**10, 10**10])\n",
    "   \n",
    "def foo(tmp):\n",
    "    tmp_max=np.max(tmp)\n",
    "    logD = np.log(np.sum(np.exp(tmp-tmp_max))) + tmp_max\n",
    "    log_v = tmp - logD\n",
    "    v = np.exp(log_v)\n",
    "    return v\n",
    "\n",
    "print(foo(tmp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  1.]\n"
     ]
    }
   ],
   "source": [
    "#numerical stable way to calculate softmax\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0)\n",
    "\n",
    "scores = [30000000000, 50000000000, 70000000000]\n",
    "print(softmax(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5.76612770e-04   1.56739601e-03   4.26062410e-03   1.15815771e-02\n",
      "   3.14819905e-02   8.55769227e-02   2.32622194e-01   6.32332683e-01]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print (softmax(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'__globals__': [], '__version__': '1.0', 'data': array([[ (array([[ (array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.01960784],\n",
      "       ..., \n",
      "       [ 0.        ,  0.        ,  0.03921569, ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.02352941, ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ]]), array([[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  1., ...,  0.,  0.,  0.],\n",
      "       ..., \n",
      "       [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  1.]]))]], \n",
      "      dtype=[('inputs', 'O'), ('targets', 'O')]), array([[ (array([[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  1., ...,  0.,  0.,  0.],\n",
      "       ..., \n",
      "       [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  1.]]), array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.05882353, ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.25490198, ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       ..., \n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ]]))]], \n",
      "      dtype=[('targets', 'O'), ('inputs', 'O')]), array([[ (array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.42745101,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.71372551,  0.01176471, ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       ..., \n",
      "       [ 0.        ,  0.70980394,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.42352945,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ]]), array([[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  1., ...,  0.,  0.,  0.],\n",
      "       ..., \n",
      "       [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  1.]]))]], \n",
      "      dtype=[('inputs', 'O'), ('targets', 'O')]))]], \n",
      "      dtype=[('training', 'O'), ('validation', 'O'), ('test', 'O')]), '__header__': b'MATLAB 5.0 MAT-file, written by Octave 3.2.4, 2012-10-31 21:15:39 UTC'}\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "x = loadmat('data.mat')\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ array([[ (array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.01960784],\n",
      "       ..., \n",
      "       [ 0.        ,  0.        ,  0.03921569, ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.02352941, ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ]]), array([[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  1., ...,  0.,  0.,  0.],\n",
      "       ..., \n",
      "       [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  1.]]))]], \n",
      "      dtype=[('inputs', 'O'), ('targets', 'O')])]]\n"
     ]
    }
   ],
   "source": [
    "print(x['data']['training'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ array([[ (array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.01960784],\n",
      "       ..., \n",
      "       [ 0.        ,  0.        ,  0.03921569, ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.02352941, ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ]]), array([[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  1., ...,  0.,  0.,  0.],\n",
      "       ..., \n",
      "       [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  1.]]))]], \n",
      "      dtype=[('inputs', 'O'), ('targets', 'O')])]]\n"
     ]
    }
   ],
   "source": [
    "#print(x['data']['training'])\n",
    "train = x['data']['training']\n",
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1)\n",
      "(1, 1)\n",
      "[[ (array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.01960784],\n",
      "       ..., \n",
      "       [ 0.        ,  0.        ,  0.03921569, ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.02352941, ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ]]), array([[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  1., ...,  0.,  0.,  0.],\n",
      "       ..., \n",
      "       [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  1.]]))]]\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)                                                                                                                       \n",
    "print(train[0,0].shape)\n",
    "print(train[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ array([[ (array([[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  1., ...,  0.,  0.,  0.],\n",
      "       ..., \n",
      "       [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  1.]]), array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.05882353, ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.25490198, ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       ..., \n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ]]))]], \n",
      "      dtype=[('targets', 'O'), ('inputs', 'O')])]]\n"
     ]
    }
   ],
   "source": [
    "print(x['data']['validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ array([[ (array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.42745101,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.71372551,  0.01176471, ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       ..., \n",
      "       [ 0.        ,  0.70980394,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.42352945,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ]]), array([[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  1., ...,  0.,  0.,  0.],\n",
      "       ..., \n",
      "       [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  1.]]))]], \n",
      "      dtype=[('inputs', 'O'), ('targets', 'O')])]]\n"
     ]
    }
   ],
   "source": [
    "print(x['data']['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ array([[ (array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.42745101,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.71372551,  0.01176471, ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       ..., \n",
      "       [ 0.        ,  0.70980394,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.42352945,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ]]), array([[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  1., ...,  0.,  0.,  0.],\n",
      "       ..., \n",
      "       [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  1.]]))]], \n",
      "      dtype=[('inputs', 'O'), ('targets', 'O')])]]\n"
     ]
    }
   ],
   "source": [
    "print(x['data']['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ array([[ (array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.42745101,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.71372551,  0.01176471, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ..., \n",
       "       [ 0.        ,  0.70980394,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.42352945,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]]), array([[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.]]))]], \n",
       "      dtype=[('inputs', 'O'), ('targets', 'O')])]], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['data']['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 2.0]\n",
      "d.targets: [1, 2, 3]\n",
      "dataset.testing: <__main__.data object at 0x106a51518>\n",
      "dataset.testing.inputs: [4, 5, 6]\n",
      "dataset.testing.targets: [1, 2, 3]\n",
      "dataset.training.inputs: [[1 1 1]\n",
      " [2 2 2]]\n",
      "dataset.training.inputs shape: (2, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class model:    \n",
    "    def __init__(self):\n",
    "        self.input_to_hid=None\n",
    "        self.hid_to_class=None\n",
    "    \n",
    "    def set_input_to_hid(self,a):\n",
    "        self.input_to_hid = a\n",
    "    def set_hid_to_class(self,a):\n",
    "        self.hid_to_class = a\n",
    "\n",
    "class data:\n",
    "    def __init__(self):\n",
    "        self.targets=None\n",
    "        self.inputs=None\n",
    "    def set_target(self,targets):\n",
    "        self.targets=targets\n",
    "    def set_inputs(self,inputs):\n",
    "        self.inputs = inputs\n",
    "\n",
    "class datas:\n",
    "    def __init__(self):\n",
    "        self.training=None\n",
    "        self.testing=None\n",
    "        self.validation=None\n",
    "    def set_train(self,train_data):\n",
    "        self.training=train_data\n",
    "    def set_test(self,test_data):\n",
    "        self.testing=test_data\n",
    "    def set_valid(self,valid_data):\n",
    "        self.validation=valid_data\n",
    "    def get_num_training_cases(self):\n",
    "        return self.training.inputs.shape[1]\n",
    "    def get(self,s):\n",
    "        if s==\"training\":\n",
    "            return self.training\n",
    "        elif s=='validation':\n",
    "            return self.validation\n",
    "        elif s=='test':\n",
    "            return self.testing\n",
    "        else:\n",
    "            print('datas get error')\n",
    "              \n",
    "m = model()\n",
    "m.set_input_to_hid([1.0,2.0])\n",
    "print(m.input_to_hid)\n",
    "\n",
    "d = data()\n",
    "d.set_target([1,2,3])\n",
    "d.set_inputs([4,5,6])\n",
    "print('d.targets:',d.targets)\n",
    "\n",
    "dataset = datas()\n",
    "dataset.set_test(d)\n",
    "print('dataset.testing:',dataset.testing)\n",
    "print('dataset.testing.inputs:',dataset.testing.inputs)\n",
    "print('dataset.testing.targets:',dataset.testing.targets)\n",
    "\n",
    "d1 = data()\n",
    "one = np.array([[1,2,3],[4,5,6]])\n",
    "two = np.array([[1,1,1],[2,2,2]])\n",
    "d1.set_target(one)\n",
    "d1.set_inputs(two)\n",
    "dataset.set_train(d1)\n",
    "print('dataset.training.inputs:',dataset.training.inputs)\n",
    "print('dataset.training.inputs shape:',dataset.training.inputs.shape)\n",
    "dataset.get_num_training_cases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "def load():\n",
    "    dt_train_target = loadmat('dt_train_target.mat')\n",
    "    dt_train_input = loadmat('dt_train_input.mat')\n",
    "    dt_test_input = loadmat('dt_test_input.mat')\n",
    "    dt_test_target = loadmat('dt_test_target.mat')\n",
    "    dt_valid_input = loadmat('dt_valid_input.mat')\n",
    "    dt_valid_target = loadmat('dt_valid_target.mat')\n",
    "\n",
    "    train_target = dt_train_target['dt_train_target']\n",
    "    train_input = dt_train_input['dt_train_input']\n",
    "    train_data = data()\n",
    "    train_data.set_inputs(train_input)\n",
    "    train_data.set_target(train_target)\n",
    "    \n",
    "    test_input = dt_test_input['dt_test_input'] \n",
    "    test_target = dt_test_target['dt_test_target']\n",
    "    test_data = data()\n",
    "    test_data.set_inputs(test_input)\n",
    "    test_data.set_target(test_target)\n",
    "\n",
    "    valid_input = dt_valid_input['dt_valid_input']\n",
    "    valid_target = dt_valid_target['dt_valid_target']\n",
    "    valid_data = data()\n",
    "    valid_data.set_inputs(valid_input)\n",
    "    valid_data.set_target(valid_target)\n",
    "    \n",
    "    dataset_load = datas()\n",
    "    dataset_load.set_train(train_data)\n",
    "    dataset_load.set_test(test_data)\n",
    "    dataset_load.set_valid(valid_data)\n",
    "    return dataset_load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test = load()\n",
    "assert(test.get_num_training_cases()==1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img src='data.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def a3(wd_coefficient, n_hid,n_iters,learning_rate,momentum_multiplier,do_early_stopping, mini_batch_size):\n",
    "    model = initial_model(n_hid)\n",
    "    dataset_a3 = load()\n",
    "    #where is the loop through training, test, validation data cases? \n",
    "    # this is funny, variable outside \n",
    "    n_training_cases = dataset_a3.get_num_training_cases()\n",
    "    print('n_training_cases:{}',n_training_cases)\n",
    "    assert(n_training_cases==1000)\n",
    "    if n_iters !=0:\n",
    "        test_gradient(model,dataset_a3.training,wd_coefficient)\n",
    "    theta = model_to_theta(model)\n",
    "    momentum_speed = theta * 0\n",
    "    training_data_losses = []\n",
    "    validataion_data_losses = []\n",
    "    if do_early_stopping:\n",
    "        print('do_early_stopping true')\n",
    "        best_so_far_theta = -1\n",
    "        best_so_far_validation_loss = 10000000 #replace inf with a large number\n",
    "        best_so_far_after_n_iters = -1\n",
    "    for optimization_iteration in range(1,n_iters):\n",
    "        print('optimization_iteration:{} n_iters:{}',optimization_iteration,n_iters)\n",
    "        model = theta_to_model(theta)\n",
    "        momentum_speed = theta * 0;\n",
    "        training_batch_start = (((optimization_iteration_i-1) * mini_batch_size) % n_training_cases)+1;\n",
    "        print('training_batch_start:',training_batch_start)\n",
    "        #training_batch_inputs = dt_train_input['dt_train_input'](:, training_batch_start : training_batch_start + mini_batch_size - 1);\n",
    "        #training_batch_targets = dt_train_target['dt_train_target'](:, training_batch_start : training_batch_start + mini_batch_size - 1);\n",
    "        #print('training_batch_inputs shape:{} training_batch_targets shape:',training_batch_inputs.shape,training_batch_targets.shape)\n",
    "        \n",
    "        gradient = model_to_theta(d_loss_by_d_model(model, training_batch, wd_coefficient));\n",
    "        momentum_speed = momentum_speed * momentum_multiplier - gradient;\n",
    "        theta = theta + momentum_speed * learning_rate;\n",
    "        model = theta_to_model(theta);\n",
    "        training_data_losses = [training_data_losses, loss(model, datas.training, wd_coefficient)];\n",
    "        validation_data_losses = [validation_data_losses, loss(model, datas.validation, wd_coefficient)];\n",
    "        if do_early_stopping and validation_data_losses(end) < best_so_far.validation_loss:\n",
    "            best_so_far.theta = theta; # this will be overwritten soon\n",
    "            best_so_far.validation_loss = validation_data_losses(end);\n",
    "            best_so_far.after_n_iters = optimization_iteration_i;\n",
    "        if optimization_iteration_i % round(n_iters/10) == 0:\n",
    "            print('After %d optimization iterations, training data loss is %f, and validation data loss is %f\\n', \n",
    "                    optimization_iteration_i, training_data_losses(end), validation_data_losses(end));\n",
    "    if n_iters != 0: \n",
    "        test_gradient(model, datas.training, wd_coefficient) \n",
    "        #end % check again, this time with more typical parameters\n",
    "    if do_early_stopping:\n",
    "        print('Early stopping: validation loss was lowest after %d iterations. We chose the model that we had then.\\n', \n",
    "        best_so_far.after_n_iters);\n",
    "        #theta = best_so_far.theta;\n",
    "    model = theta_to_model(theta)\n",
    "    #data_list = ['training','validation','test']\n",
    "    data_list = ['training']\n",
    "    for x in data_list:\n",
    "        input_data_set = dataset_a3.get(x)\n",
    "        print('the loss on {} is {}',x,loss(model,input_data_set,wd_coefficient))\n",
    "        \n",
    "def initial_model(n_hid):\n",
    "    \"\"\"\n",
    "    initial_model(0) creates model.input_to_hid={0x256} and model.hid_to_class=(10x0). A numpy 0 dimension\n",
    "    is an empty matrix with allocated shape. Just like in octave!\n",
    "    \n",
    "    octave starts array indexing from 1, numpy from 0. octave range = n_params-1 and numpy range 0,n_params\n",
    "    which is same as range(n_params)\n",
    "    the octave code creates a vector from 0 to n_params-1 and does a cos on the range\n",
    "    \"\"\"\n",
    "    if n_hid==0:\n",
    "        m = model()\n",
    "        m.set_input_to_hid(np.zeros(shape=(0,256)))\n",
    "        m.set_hid_to_class(np.zeros(shape=(10,0)))\n",
    "        return m\n",
    "    \n",
    "    n_params = (256+10)*n_hid\n",
    "    #print(\"n_params:\",n_params)\n",
    "    as_row_vector = np.cos(np.array(range(0,n_params)))\n",
    "    #as_row_vector = (np.array(range(0,n_params)))\n",
    "    \n",
    "    #print('as_row_vector shape:',as_row_vector.shape)\n",
    "    #print('as_row_vector:',as_row_vector[0:20])\n",
    "    \n",
    "    m_theta =  theta_to_model(as_row_vector * 0.1 )\n",
    "    #m_theta =  theta_to_model(as_row_vector  )\n",
    "    \n",
    "    #print('initial_model model input_to_hid shape:', m_theta.input_to_hid.shape)\n",
    "    return m_theta\n",
    "\n",
    "#divide into 2 parts, the first 256 and the second 10; the 2 sets of weights are concatenated together\n",
    "#theta is some vector.. which can be split into 1 parts. Becareful of octave start 0 numpy from 1\n",
    "def theta_to_model(theta):\n",
    "    \n",
    "    #print('theta shape:', theta.shape)\n",
    "    n_hid = (theta.shape[0]/(256+10))\n",
    "    n_hid = int(n_hid)\n",
    "    #print('theta_to_model n_hid:%f',n_hid)\n",
    "    if(n_hid==0):\n",
    "        m = model()\n",
    "        m.set_input_to_hid(np.zeros(shape=(0,256)))\n",
    "        m.set_hid_to_class(np.zeros(shape=(10,0)))\n",
    "        return m\n",
    "        \n",
    "    #reshape changes the order...the reshape then tranpose are a problem...\n",
    "    input_to_hid = (theta[0:(256*n_hid)]).reshape(n_hid,-1)\n",
    "    #print('input_to_hid shape:',input_to_hid.shape)\n",
    "    #print('input_to_hid before reshape!!!!:', input_to_hid)\n",
    "    #print('hid to class before reshape:', theta[256*n_hid:])\n",
    "    if(n_hid==1):\n",
    "        hid_to_class = np.transpose(theta[256*n_hid:].reshape(1,-1))\n",
    "    else:\n",
    "        hid_to_class = theta[256*n_hid:].reshape(-1,n_hid)\n",
    "    #print('after reshape input_to_hid shape:', input_to_hid.shape)\n",
    "    #print('after reshape hid_to_class shape:', hid_to_class.shape)\n",
    "    \n",
    "    m = model()\n",
    "    m.set_input_to_hid(input_to_hid)\n",
    "   \n",
    "    m.set_hid_to_class(hid_to_class)\n",
    "    #print('input_to_hid final:{}',m.input_to_hid)\n",
    "    #print('hid_to_class final:{}', m.hid_to_class)\n",
    "    return m\n",
    "\n",
    "#this should be 2 dim not 1 dim. Add newaxis? \n",
    "def model_to_theta(model):\n",
    "    input_to_hid = model.input_to_hid\n",
    "    hid_to_class = model.hid_to_class\n",
    "    flat_input_to_hid = model.input_to_hid.flatten()\n",
    "    flat_hid_to_class = model.hid_to_class.flatten()\n",
    "    return np.transpose(np.concatenate((flat_input_to_hid, flat_hid_to_class),axis=0)[np.newaxis])\n",
    "\n",
    "def logistic(x):\n",
    "    return 1./(1+np.exp(np.negative(x)))\n",
    "\n",
    "#equivalent to log(sum(exp(A)))\n",
    "def log_sum_exp_over_rows(x):\n",
    "    maxs_small = x.max(0)\n",
    "    maxs_big = np.matlib.repmat(maxs_small, x.shape[0],1)\n",
    "    ret = np.log(np.sum(np.exp(x-maxs_big),axis=0))+ maxs_small\n",
    "                 \n",
    "    return ret\n",
    "\n",
    "#mapping from octave model.input_to_hid->input_to_hid, model.hid_to_class->hid_to_class\n",
    "#data.inputs->data_input, data.targets->data_targets, data_input,data_targets for test, validation, target\n",
    "#data sets. \n",
    "def loss(model, data, wd_coefficient):\n",
    "    print('loss model.input_to_hid shape:{} model.hid_to_class shape:{}'.format(model.input_to_hid.shape, model.hid_to_class.shape))\n",
    "    print('loss sum model.input_to_hid: {} , sum model.hid_to_class:{}'.format(np.sum(model.input_to_hid), np.sum(model.hid_to_class)))\n",
    "    print('loss data.inputs sum:{}, data_input.shape {}'.format(np.sum(data.inputs),(data.inputs).shape))\n",
    "    \n",
    "    hid_input = np.dot(model.input_to_hid, data.inputs)\n",
    "    #print('hid_input shape: {}, sum hid_dot:{},'.format(hid_input.shape, np.sum(hid_input)))\n",
    "    hid_output = logistic(hid_input)\n",
    "    #print('hid_output shape: {} sum hid_output: {}'.format(hid_output.shape, np.sum(hid_output)))\n",
    "\n",
    "    class_input = np.dot(model.hid_to_class,hid_output)\n",
    "    #print('class_input shape:{}, sum class_input:{}',class_input.shape,np.sum(class_input))\n",
    "    class_normalizer = log_sum_exp_over_rows(class_input)\n",
    "    #print('class_normalizer shape:',class_normalizer.shape)\n",
    "    #print('sum class_normalizer:', np.sum(class_normalizer))\n",
    "    log_class_prob = class_input - np.matlib.repmat(class_normalizer, class_input.shape[0],1)\n",
    "    #print('log_class_prob shape:{} sum log_class_prob {}'.format(log_class_prob.shape,np.sum(log_class_prob)))\n",
    "    \n",
    "    test_multiply = np.multiply(log_class_prob, data.targets)\n",
    "    #print('test_mutiply shape:', test_multiply.shape)\n",
    "   \n",
    "    test_sum = np.sum(test_multiply,0)\n",
    "    #print('test_sum shape:',test_sum.shape)\n",
    "    class_loss = -np.mean(test_sum)\n",
    "    print('classification_loss:', class_loss)\n",
    "    wd_loss = np.sum(np.square(model_to_theta(model))) / (2*wd_coefficient)\n",
    "    print('wd_loss:', wd_loss)\n",
    "    \n",
    "    return class_loss + wd_loss\n",
    "    \n",
    "\n",
    "def test_gradient(model,data,wd_coefficient):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    base_theta = model_to_theta(model)\n",
    "    h = 1e-2\n",
    "    correctness_threshold = 1e-5\n",
    "    analytic_gradient = model_to_theta(d_loss_by_d_model(model,data,wd_coefficient))\n",
    "    for i in range(100):\n",
    "        test_index = (i * 1299721) % base_theta.shape[0] + 1\n",
    "        print(\"i:{} test_index:{}\", i, test_index)\n",
    "        analytic_here = analytic_gradient(test_index)\n",
    "        theta_step = base_theta * 0\n",
    "        theta_step[test_index] = h\n",
    "        #contribution_distances = [-4:1, 1:4]\n",
    "        contribution_weights = [1/280,-4/105,1/5,4/5,-1/5,4/105,-1/280]\n",
    "        temp = 0\n",
    "        for contribution_index in range(0,8):\n",
    "            '''\n",
    "            '''\n",
    "            temp = temp + loss(theta_to_model(base_theta + theta_step * contribution_distances(contribution_index)),\n",
    "                          data,wd_coefficient) * contribution_weights(contribution_index)\n",
    "        #fd_here = temp/h\n",
    "        #diff = np.abs(analytic_here - fd_here)\n",
    "        # print('diff:{}',diff)\n",
    "        #print('correctness_threshold:{}',correctness_threshold)\n",
    "\n",
    "def d_loss_by_d_model(model,data,wd_coefficient):\n",
    "    '''\n",
    "    '''\n",
    "    m = data.inputs.shape[1]\n",
    "    print('data.inputs.shape:', data.inputs.shape[1])\n",
    "    print('model.input_to_hid shape:{}, model.hid_to_class shape:{}',model.input_to_hid.shape,model.hid_to_class.shape)\n",
    "    print('sum model.input_to_hid{} sum model.hid_to_class:',np.sum(model.input_to_hid), np.sum(model.hid_to_class))\n",
    "    hid_input = np.dot(model.input_to_hid, data.inputs)\n",
    "    print('hid_input shape:', hid_input.shape)\n",
    "    print('hid_input:',hid_input)\n",
    "    hid_output = logistic(hid_input)\n",
    "    class_input = np.dot(model.hid_to_class,hid_output)\n",
    "    class_normalizer = log_sum_exp_over_rows(class_input)\n",
    "    print('hid_output shape:',hid_output.shape)\n",
    "    print('hid_output:',hid_output)\n",
    "    print('class_input shape:', class_input.shape)\n",
    "    print('class_input:',class_input)\n",
    "    \n",
    "    log_class_prob = class_input - np.matlib.repmat(class_normalizer, class_input.shape[0],1)\n",
    "    class_output = np.exp(log_class_prob)\n",
    "    \n",
    "    print('log_class_prob shape:',log_class_prob.shape)\n",
    "    print('log_class_prob',log_class_prob)\n",
    "    print('class_output shape',class_output.shape)\n",
    "    print('class output:',class_output)\n",
    "    \n",
    "    delta_3 = class_output - data.targets\n",
    "    print('model.hid_to_class shape:', model.hid_to_class.shape)\n",
    "    print('delta3 shape:', delta_3.shape)\n",
    "    print('hid_input shape:', hid_input.shape)\n",
    "    temp = np.transpose(model.hid_to_class)\n",
    "    temp1 = np.dot(temp,delta_3)\n",
    "    print('temp shape:',temp.shape)\n",
    "    print('temp1 shape:',temp1.shape)\n",
    "    temp2 = logistic(hid_input)\n",
    "    temp3 = 1-logistic(hid_input)\n",
    "    print('temp2 shape:',temp2.shape)\n",
    "    print('temp3 shape:',temp3.shape)\n",
    "    temp4 = np.dot(temp2,temp3)\n",
    "    print('temp4 shape:',temp4.shape)\n",
    "    \n",
    "    delta_2 = np.dot(np.transpose(model.hid_to_class),delta_3) * np.dot(logistic(hid_input), 1-logistic(hid_input))\n",
    "    \n",
    "    ret_input_to_hid = 1/m * np.dot(delta_2, np.transpose(data.inputs)) + np.dot(wd_coefficient,model.input_to_hid)\n",
    "    \n",
    "    ret_hid_to_class = 1/m * np.dot(delta_3,np.transpose(hid_output)) + np.dot(wd_coefficient, model.hid_to_class)\n",
    "    \n",
    "    m = model()\n",
    "    m.set_input_to_hid(ret_input_to_hid)\n",
    "    m.set_hid_to_class(ret_hid_to_class)\n",
    "    return m\n",
    "\n",
    "def classification_performance(model,data):\n",
    "    hid_input = np.dot(model.input_to_hid,data.inputs)\n",
    "    hid_output = logistic(hid_input)\n",
    "    class_input  = np.dot(model.hid_to_class, hid_output)\n",
    "    print('is this a tuple? max class_input:{}', np.max(class_input))\n",
    "    print('is this a tuple? max data.targets:{}', np.max(data.targets))\n",
    "    choices = np.max(class_input)\n",
    "    targets = max(data.targets)\n",
    "    #this is fucked up\n",
    "    test = mean((double)(choices = choices != targets))\n",
    "    \n",
    "#foo = np.array([ 4.04858735,  5.04858735,  6.04858735])\n",
    "#print(foo)\n",
    "#np.testing.assert_array_equal(np.array([1]),np.array([1]))\n",
    "#np.testing.assert_array_equal(test_logsumexp,np.array([ 4.04858735,  5.04858735,  6.04858735]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss model.input_to_hid shape:(7, 256) model.hid_to_class shape:(10, 7)\n",
      "loss sum model.input_to_hid: 0.12424418845958893 , sum model.hid_to_class:0.02945803379470418\n",
      "loss data.inputs sum:63213.010485252365, data_input.shape (256, 1000)\n",
      "classification_loss: 2.30278784125\n",
      "wd_loss: 4.65593640453e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.3027883068455828"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load()\n",
    "data1 = dataset.get('training')\n",
    "loss(initial_model(7),data1,10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1862, 1)\n",
      "4.65593640453e-07\n"
     ]
    }
   ],
   "source": [
    "a = np.square(model_to_theta(initial_model(7)))\n",
    "print(a.shape)\n",
    "print(np.sum(a)/(2*1e7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_training_cases:{} 1000\n",
      "loss model.input_to_hid shape:(7, 256) model.hid_to_class shape:(10, 7)\n",
      "loss sum model.input_to_hid: 0.12424418845958893 , sum model.hid_to_class:0.02945803379470418\n",
      "loss data.inputs sum:63213.010485252365, data_input.shape (256, 1000)\n",
      "classification_loss: 2.30278784125\n",
      "wd_loss: 4.65593640453e-07\n",
      "the loss on {} is {} training 2.30278830685\n"
     ]
    }
   ],
   "source": [
    "#wd_loss: 4.65593640453e-07 agrees with octave\n",
    "a3(1e7,7,0,0,0,False,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_training_cases:{} 1000\n",
      "data.inputs.shape: 1000\n",
      "model.input_to_hid shape:{}, model.hid_to_class shape:{} (7, 256) (10, 7)\n",
      "sum model.input_to_hid{} sum model.hid_to_class: 0.12424418846 0.0294580337947\n",
      "hid_input shape: (7, 1000)\n",
      "hid_input: [[ 0.19956766 -0.05615722  0.0004786  ...,  0.00121419  0.19539019\n",
      "   0.08051237]\n",
      " [ 0.11433412 -0.00538245 -0.21336224 ...,  0.04192101 -0.07499234\n",
      "   0.24803549]\n",
      " [-0.20866654  0.05658556  0.01650109 ..., -0.00455033 -0.18942219\n",
      "  -0.10025141]\n",
      " ..., \n",
      " [ 0.2164439  -0.05665553 -0.03337628 ...,  0.00785765  0.18225453\n",
      "   0.11935554]\n",
      " [ 0.08050319  0.00362945 -0.20939292 ...,  0.04093356 -0.10457094\n",
      "   0.23055884]\n",
      " [-0.22285046  0.0563667   0.05004008 ..., -0.0111152  -0.17393262\n",
      "  -0.13770376]]\n",
      "hid_output shape: (7, 1000)\n",
      "hid_output: [[ 0.54972698  0.48596438  0.50011965 ...,  0.50030355  0.54869273\n",
      "   0.52011723]\n",
      " [ 0.52855243  0.49865439  0.44686088 ...,  0.51047872  0.4812607\n",
      "   0.56169291]\n",
      " [ 0.44802183  0.51414262  0.50412518 ...,  0.49886242  0.45278554\n",
      "   0.47495812]\n",
      " ..., \n",
      " [ 0.55390071  0.4858399   0.49165671 ...,  0.5019644   0.54543793\n",
      "   0.52980351]\n",
      " [ 0.52011493  0.50090736  0.4478422  ...,  0.51023196  0.47388106\n",
      "   0.55738573]\n",
      " [ 0.44451681  0.51408794  0.51250741 ...,  0.49722123  0.45662614\n",
      "   0.46562836]]\n",
      "class_input shape: (10, 1000)\n",
      "class_input: [[ 0.02254967  0.0132852   0.0108681  ...,  0.01575942  0.01881793\n",
      "   0.02185555]\n",
      " [-0.00543463 -0.01238495 -0.0090512  ..., -0.01097708 -0.00409971\n",
      "  -0.01009563]\n",
      " [-0.03074403 -0.03195929 -0.02451554 ..., -0.03231072 -0.0249995\n",
      "  -0.03707778]\n",
      " ..., \n",
      " [ 0.03934715  0.03651269  0.02830112 ...,  0.03792052  0.03220332\n",
      "   0.04514523]\n",
      " [ 0.03704984  0.02911806  0.02296264 ...,  0.03159227  0.03057271\n",
      "   0.03974232]\n",
      " [ 0.01651676  0.00739165  0.00632205 ...,  0.00971445  0.01389435\n",
      "   0.01477842]]\n",
      "log_class_prob shape: (10, 1000)\n",
      "log_class_prob [[-2.28281651 -2.29086683 -2.29295152 ..., -2.2887156  -2.28603314\n",
      "  -2.28345589]\n",
      " [-2.31080081 -2.31653698 -2.31287082 ..., -2.31545211 -2.30895078\n",
      "  -2.31540707]\n",
      " [-2.33611021 -2.33611131 -2.32833517 ..., -2.33678574 -2.32985057\n",
      "  -2.34238922]\n",
      " ..., \n",
      " [-2.26601903 -2.26763933 -2.2755185  ..., -2.2665545  -2.27264775\n",
      "  -2.26016621]\n",
      " [-2.26831634 -2.27503397 -2.28085698 ..., -2.27288275 -2.27427836\n",
      "  -2.26556912]\n",
      " [-2.28884942 -2.29676038 -2.29749757 ..., -2.29476057 -2.29095672\n",
      "  -2.29053302]]\n",
      "class_output shape (10, 1000)\n",
      "class output: [[ 0.10199653  0.10117872  0.10096801 ...,  0.10139661  0.10166897\n",
      "   0.10193133]\n",
      " [ 0.09918179  0.0986145   0.0989767  ...,  0.09872154  0.09936545\n",
      "   0.09872599]\n",
      " [ 0.09670306  0.09670296  0.09745786 ...,  0.09663776  0.09731029\n",
      "   0.09609777]\n",
      " ..., \n",
      " [ 0.10372428  0.10355635  0.10274362 ...,  0.10366876  0.103039\n",
      "   0.10433314]\n",
      " [ 0.10348627  0.10279342  0.10219659 ...,  0.10301479  0.10287112\n",
      "   0.10377096]\n",
      " [ 0.10138304  0.10058417  0.10051005 ...,  0.10078552  0.10116962\n",
      "   0.1012125 ]]\n",
      "model.hid_to_class shape: (10, 7)\n",
      "delta3 shape: (10, 1000)\n",
      "hid_input shape: (7, 1000)\n",
      "temp shape: (7, 10)\n",
      "temp1 shape: (7, 1000)\n",
      "temp2 shape: (7, 1000)\n",
      "temp3 shape: (7, 1000)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (7,1000) and (7,1000) not aligned: 1000 (dim 1) != 7 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-e395b9277de1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-e968dae471f6>\u001b[0m in \u001b[0;36ma3\u001b[0;34m(wd_coefficient, n_hid, n_iters, learning_rate, momentum_multiplier, do_early_stopping, mini_batch_size)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_training_cases\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_iters\u001b[0m \u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mtest_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataset_a3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwd_coefficient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_to_theta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mmomentum_speed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-e968dae471f6>\u001b[0m in \u001b[0;36mtest_gradient\u001b[0;34m(model, data, wd_coefficient)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0mcorrectness_threshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m     \u001b[0manalytic_gradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_to_theta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_loss_by_d_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwd_coefficient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mtest_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1299721\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbase_theta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-e968dae471f6>\u001b[0m in \u001b[0;36md_loss_by_d_model\u001b[0;34m(model, data, wd_coefficient)\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'temp2 shape:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtemp2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'temp3 shape:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtemp3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m     \u001b[0mtemp4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtemp3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'temp4 shape:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtemp4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (7,1000) and (7,1000) not aligned: 1000 (dim 1) != 7 (dim 0)"
     ]
    }
   ],
   "source": [
    "a3(1e7,7,10,0,0,False,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "A=[[1,2,3],[4,5,6]]\n",
    "test_logistic = logistic(A)\n",
    "print(type(test_logistic))\n",
    "print(\"test_logistic shape:\",test_logistic.shape)\n",
    "print (\"test_logistic:\",test_logistic)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h6>verify logistic</h6>\n",
    "<img src=\"verify2.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_zero_model = initial_model(0)\n",
    "print(test_zero_model.input_to_hid.shape)\n",
    "print(test_zero_model.hid_to_class.shape)\n",
    "test_zero_theta = model_to_theta(test_zero_model)\n",
    "print(test_zero_theta.shape)\n",
    "is_this_zero_model = theta_to_model(test_zero_theta)\n",
    "print(is_this_zero_model.input_to_hid.shape)\n",
    "print(is_this_zero_model.hid_to_class.shape)\n",
    "#verify hid_to_shape = (0,256) for both test_zero_model and is_this_zero_model\n",
    "#verify hid_to_class = (10,0) for both test_zero_model and is_this_zero_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.input_to_hid shape: (7, 256)\n",
      "sum input_to_hid: 1604736\n"
     ]
    }
   ],
   "source": [
    "a = initial_model(7)\n",
    "print('model.input_to_hid shape:', (a.input_to_hid).shape)\n",
    "print('sum input_to_hid:', np.sum(a.input_to_hid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a = initial_model(1)\n",
    "print(a.input_to_hid.shape)\n",
    "print(a.hid_to_class.shape)\n",
    "theta_one = model_to_theta(a)\n",
    "print('theta shape', theta_one.shape)\n",
    "model_one = theta_to_model(theta_1)\n",
    "print(model_one.input_to_hid.shape)\n",
    "print(model_one.hid_to_class.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h6>Initial Model(1)</h6>\n",
    "<img src=\"im1a.png\">\n",
    "<img src=\"im1b.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img arc=\"verify3.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "A=[[1,2,3],[4,5,6]]\n",
    "test_logsumexp = log_sum_exp_over_rows(A)\n",
    "print(type(test_logsumexp))\n",
    "print(\"test_logsumexp:\",test_logsumexp.shape)\n",
    "print (\"test_logsumexp:\",test_logsumexp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h6>verify log_sum_exp_over_rows</h6>\n",
    "<img src=\"verify1.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a = initial_model(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_model = initial_model(2)\n",
    "theta = model_to_theta(test_model)\n",
    "print('theta',theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "m = initial_model(10)\n",
    "print('a.input_to_hid shape:{} a.hid_to_class shape:{}', m.input_to_hid.shape, m.hid_to_class.shape)\n",
    "print(np.sum(m.input_to_hid))\n",
    "print(np.sum(m.hid_to_class))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h6>notes</h6>\n",
    "in octave from_data_file = load('data.mat')\n",
    "<p></p>\n",
    "in octave datas = data_file.data\n",
    "<p></p>\n",
    "in octave, datas2 = {datas.training, datas.validation, datas.test}\n",
    "<p></p>\n",
    "data=datas2{data_i}\n",
    "<p></p>\n",
    "then loss is called with loss(model,data,wd_coefficient) or\n",
    "loss(model,datas.training,wd_coefficient) then loss(model,datas.validation,wd_coefficient) \n",
    "then loss(model,datas.test,wd_coefficient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "train_target = dt_train_target['dt_train_target']\n",
    "train_input = dt_train_input['dt_train_input']\n",
    "traindata = data()\n",
    "traindata.set_inputs(train_input)\n",
    "traindata.set_target(train_target)\n",
    "print ('train_target shape:',train_target.shape)\n",
    "print ('train_input shape:',train_input.shape)\n",
    "a = loss(m, traindata, 0)\n",
    "print(a)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_input = dt_test_input['dt_test_input'] \n",
    "test_target = dt_test_target['dt_test_target']\n",
    "test_data = data()\n",
    "test_data.set_inputs(test_input)\n",
    "test_data.set_target(test_target)\n",
    "\n",
    "a = loss(m, test_data, 0)\n",
    "print(a)\n",
    "valid_input = dt_valid_input['dt_valid_input']\n",
    "valid_target = dt_valid_target['dt_valid_target']\n",
    "valid_data = data()\n",
    "valid_data.set_inputs(valid_input)\n",
    "valid_data.set_target(valid_target)\n",
    "\n",
    "a = loss(m, valid_data, 0)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Person(object):  \n",
    "    def __init__(self, first_name, last_name):\n",
    "        self.first_name = first_name\n",
    "        self.last_name = last_name\n",
    "\n",
    "    @property\n",
    "    def full_name(self):\n",
    "        return self.first_name + ' ' + self.last_name\n",
    "\n",
    "    @full_name.setter\n",
    "    def full_name(self, value):\n",
    "        first_name, last_name = value.split(' ')\n",
    "        self.first_name = first_name\n",
    "        self.last_name = last_name\n",
    "\n",
    "    @full_name.deleter\n",
    "    def full_name(self):\n",
    "        del self.first_name\n",
    "        del self.last_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "p = Person('a','b')\n",
    "print(p.full_name)\n",
    "p.full_name='aa bb'\n",
    "print(p.full_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
