{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Momentum vs. SGD for optimization</h6>\n",
    "<img src=\"mom1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Numerical Stability for calculating exponent divided by sum of exponents</h6>\n",
    "https://stackoverflow.com/questions/10278004/how-to-order-this-computation-for-numerical-stability\n",
    "\n",
    "<p>Do not calculate np.exp(x) directly, subtract x_max first</p>\n",
    "<p>tmp = np.array([-10**10, 10**10])</p>\n",
    "<p>tmp_max = tmp.max()</p>\n",
    "<p>logD = np.log(np.sum(np.exp(tmp-tmp_max))) + tmp_max</p>\n",
    "<p>log_v = tmp - log_D</p>\n",
    "<p>v = np.exp(log_v)</p>\n",
    "<p>>>> v\n",
    "array([ 0.,  1.])</p>\n",
    "<p></p>\n",
    "\n",
    "$log\\sum_{k=1}^{training set}exp(tmp-tmp_{max}) + tmp_{max}$\n",
    "\n",
    "$=log\\sum_{k=1}^{training set} \\frac{exp(tmp)}{exp(tmp_{max})} + tmp_{max}$\n",
    "\n",
    "$= log\\frac{1}{exp(tmp_{max})} \\sum_{k=1}^{training set}exp(tmp) + tmp_{max}$ \n",
    "\n",
    "$= log[exp(-tmp_{max}) \\sum_{k=1}^{training set} exp(tmp)] + tmp_{max}$\n",
    "\n",
    "$= logexp(-tmp_{max}) + log\\sum_{k=1}^{training set}exp(tmp) + tmp_{max}$\n",
    "\n",
    "$= -tmp_{max} + log\\sum_{k=1}^{training set} exp(tmp) + tmp_{max}$\n",
    "\n",
    "<p>The above sould reduce to summation exp(tmp)</p>\n",
    "<p>Below for fraction of exp(tmp)/summation(exp(tmp))</p>\n",
    "<p>Combine log_v = tmp=log_D and v=exp(log_v)</p>\n",
    "$v=exp(tmp-logD) = \\frac{exp(tmp)}{log_D}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reference: http://cs231n.github.io/linear-classify/#softmax\n",
    "\n",
    "$\\frac{exp(x)}{\\sum_{k=1}^{K} exp(x)}$\n",
    "<p></p>\n",
    "\n",
    "$\\frac{C * exp(x)}{C*\\sum_{k=1}^{K}exp(x)}$\n",
    "\n",
    "$\\frac{exp(x + logC)}{\\sum_{k=1}^{K}exp(x+logC)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5.76612770e-04   1.56739601e-03   4.26062410e-03   1.15815771e-02\n",
      "   3.14819905e-02   8.55769227e-02   2.32622194e-01   6.32332683e-01]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "tmp=[1,2,3,4,5,6,7,8]\n",
    "#tmp = np.array([-10**10, 10**10])\n",
    "   \n",
    "def foo(tmp):\n",
    "    tmp_max=np.max(tmp)\n",
    "    logD = np.log(np.sum(np.exp(tmp-tmp_max))) + tmp_max\n",
    "    log_v = tmp - logD\n",
    "    v = np.exp(log_v)\n",
    "    return v\n",
    "\n",
    "print(foo(tmp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  1.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0)\n",
    "\n",
    "scores = [30000000000, 50000000000, 70000000000]\n",
    "print(softmax(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5.76612770e-04   1.56739601e-03   4.26062410e-03   1.15815771e-02\n",
      "   3.14819905e-02   8.55769227e-02   2.32622194e-01   6.32332683e-01]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print (softmax(tmp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from scipy.io import loadmat\n",
    "x = loadmat('data.mat')\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ array([[ (array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.01960784],\n",
      "       ..., \n",
      "       [ 0.        ,  0.        ,  0.03921569, ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.02352941, ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ]]), array([[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  1., ...,  0.,  0.,  0.],\n",
      "       ..., \n",
      "       [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  1.]]))]],\n",
      "      dtype=[('inputs', 'O'), ('targets', 'O')])]]\n"
     ]
    }
   ],
   "source": [
    "print(x['data']['training'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ array([[ (array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.01960784],\n",
      "       ..., \n",
      "       [ 0.        ,  0.        ,  0.03921569, ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.02352941, ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ]]), array([[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  1., ...,  0.,  0.,  0.],\n",
      "       ..., \n",
      "       [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  1.]]))]],\n",
      "      dtype=[('inputs', 'O'), ('targets', 'O')])]]\n"
     ]
    }
   ],
   "source": [
    "#print(x['data']['training'])\n",
    "train = x['data']['training']\n",
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1)\n",
      "(1, 1)\n",
      "[[ (array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.01960784],\n",
      "       ..., \n",
      "       [ 0.        ,  0.        ,  0.03921569, ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.02352941, ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ]]), array([[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  1., ...,  0.,  0.,  0.],\n",
      "       ..., \n",
      "       [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  1.]]))]]\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)                                                                                                                       \n",
    "print(train[0,0].shape)\n",
    "print(train[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ array([[ (array([[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  1., ...,  0.,  0.,  0.],\n",
      "       ..., \n",
      "       [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  1.]]), array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.05882353, ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.25490198, ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       ..., \n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ]]))]],\n",
      "      dtype=[('targets', 'O'), ('inputs', 'O')])]]\n"
     ]
    }
   ],
   "source": [
    "print(x['data']['validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ array([[ (array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.42745101,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.71372551,  0.01176471, ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       ..., \n",
      "       [ 0.        ,  0.70980394,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.42352945,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ]]), array([[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  1., ...,  0.,  0.,  0.],\n",
      "       ..., \n",
      "       [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  1.]]))]],\n",
      "      dtype=[('inputs', 'O'), ('targets', 'O')])]]\n"
     ]
    }
   ],
   "source": [
    "print(x['data']['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ array([[ (array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.42745101,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.71372551,  0.01176471, ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       ..., \n",
      "       [ 0.        ,  0.70980394,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.42352945,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ]]), array([[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  1., ...,  0.,  0.,  0.],\n",
      "       ..., \n",
      "       [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  1.]]))]],\n",
      "      dtype=[('inputs', 'O'), ('targets', 'O')])]]\n"
     ]
    }
   ],
   "source": [
    "print(x['data']['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ array([[ (array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.42745101,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.71372551,  0.01176471, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ..., \n",
       "       [ 0.        ,  0.70980394,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.42352945,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]]), array([[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.]]))]],\n",
       "      dtype=[('inputs', 'O'), ('targets', 'O')])]], dtype=object)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['data']['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "dt_train_target = loadmat('dt_train_target.mat')\n",
    "dt_train_input = loadmat('dt_train_input.mat')\n",
    "dt_test_input = loadmat('dt_test_input.mat')\n",
    "dt_train_target = loadmat('dt_test_target.mat')\n",
    "dt_valid_input = loadmat('dt_valid_input.mat')\n",
    "dt_valid_target = loadmat('dt_valid_target.mat')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dt_train_input.keys()\n",
    "dt_train_input['dt_train_input'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(3,)\n",
      "[ 4.04858735  5.04858735  6.04858735]\n",
      "[ 4.04858735  5.04858735  6.04858735]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "\nArrays are not equal\n\n(mismatch 100.0%)\n x: array([ 4.048587,  5.048587,  6.048587])\n y: array([ 4.048587,  5.048587,  6.048587])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-114-7e747a8e605f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfoo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;31m#np.testing.assert_array_equal(np.array([1]),np.array([1]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_array_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_logsumexp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0;36m4.04858735\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m5.04858735\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m6.04858735\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.4/site-packages/numpy/testing/utils.py\u001b[0m in \u001b[0;36massert_array_equal\u001b[0;34m(x, y, err_msg, verbose)\u001b[0m\n\u001b[1;32m    852\u001b[0m     \u001b[0m__tracebackhide__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# Hide traceback for py.test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m     assert_array_compare(operator.__eq__, x, y, err_msg=err_msg,\n\u001b[0;32m--> 854\u001b[0;31m                          verbose=verbose, header='Arrays are not equal')\n\u001b[0m\u001b[1;32m    855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.4/site-packages/numpy/testing/utils.py\u001b[0m in \u001b[0;36massert_array_compare\u001b[0;34m(comparison, x, y, err_msg, verbose, header, precision, equal_nan, equal_inf)\u001b[0m\n\u001b[1;32m    776\u001b[0m                                 names=('x', 'y'), precision=precision)\n\u001b[1;32m    777\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 778\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    779\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: \nArrays are not equal\n\n(mismatch 100.0%)\n x: array([ 4.048587,  5.048587,  6.048587])\n y: array([ 4.048587,  5.048587,  6.048587])"
     ]
    }
   ],
   "source": [
    "def a3(wd_coefficient, n_hid,n_iters,learning_rate,momentum_multiplier,do_early_stopping, mini_batch_size):\n",
    "    model = initial_model(n_hid)\n",
    "    from_data_file = load('data.mat')\n",
    "    datas = from_data_file.data\n",
    "    n_training_cases = dt_train_input['dt_train_input'].shape[1]\n",
    "    assert(n_training_cases==1000)\n",
    "    if n_iters !=0:\n",
    "        test_gradient(model,datas.training,wd_coefficient)\n",
    "\n",
    "    theta = model_to_theta(model)\n",
    "    momentum_speed = theta * 0\n",
    "    training_data_losses = []\n",
    "    validataion_data_losses = []\n",
    "    if do_early_stopping:\n",
    "        best_so_far_theta = -1\n",
    "        best_so_far_validation_loss = inf\n",
    "        best_so_far_after_n_iters = -1\n",
    "    for optimizationn_iteration in range(n_iters):\n",
    "        model = theta_to_model(theta)\n",
    "        momentum_speed = theta * 0;\n",
    "    \n",
    "        training_batch_start = mod((optimization_iteration_i-1) * mini_batch_size, n_training_cases)+1;\n",
    "        training_batch.inputs = datas.training.inputs(:, training_batch_start : training_batch_start + mini_batch_size - 1);\n",
    "        training_batch.targets = datas.training.targets(:, training_batch_start : training_batch_start + mini_batch_size - 1);\n",
    "        gradient = model_to_theta(d_loss_by_d_model(model, training_batch, wd_coefficient));\n",
    "        momentum_speed = momentum_speed * momentum_multiplier - gradient;\n",
    "        theta = theta + momentum_speed * learning_rate;\n",
    "\n",
    "        model = theta_to_model(theta);\n",
    "        training_data_losses = [training_data_losses, loss(model, datas.training, wd_coefficient)];\n",
    "        validation_data_losses = [validation_data_losses, loss(model, datas.validation, wd_coefficient)];\n",
    "        if do_early_stopping && validation_data_losses(end) < best_so_far.validation_loss,\n",
    "            best_so_far.theta = theta; % this will be overwritten soon\n",
    "            best_so_far.validation_loss = validation_data_losses(end);\n",
    "            best_so_far.after_n_iters = optimization_iteration_i;\n",
    "        end\n",
    "        if mod(optimization_iteration_i, round(n_iters/10)) == 0,\n",
    "          fprintf('After %d optimization iterations, training data loss is %f, and validation data loss is %f\\n', optimization_iteration_i, training_data_losses(end), validation_data_losses(end));\n",
    "        end\n",
    "    end\n",
    "  if n_iters ~= 0, test_gradient(model, datas.training, wd_coefficient); end % check again, this time with more typical parameters\n",
    "  if do_early_stopping:\n",
    "    fprintf('Early stopping: validation loss was lowest after %d iterations. We chose the model that we had then.\\n', best_so_far.after_n_iters);\n",
    "    theta = best_so_far.theta;\n",
    "  end\n",
    "\n",
    "def initial_model(n_hid):\n",
    "    n_params = 256+10\n",
    "    #octave starts array indexing from 1, numpy from 0. octave range = n_params-1 and numpy range 0,n_params\n",
    "    #which is same as range(n_params)\n",
    "    #the octave code creates a vector from 0 to n_params-1 and does a cos on the range\n",
    "    #as_row_vector = cos(0:(n_params-1))\n",
    "    as_row_vector = np.cos(np.array(range(0,n_params)))\n",
    "    print(as_row_vector.shape)\n",
    "    #does numpy create transpose also? No, this is tricky, numpy shows a transpose for 2d arrays not 1d\n",
    "    transpose = np.transpose(np.array(as_row_vector))\n",
    "    foo =  theta_to_model(transpose * 0.1)\n",
    "    return foo\n",
    "\n",
    "#divide into 2 parts, the first 256 and the second 10; the 2 sets of weights are concatenated together\n",
    "def theta_to_model(theta):\n",
    "    n_hid = theta.shape[0]\n",
    "    #lets assume n_hid=1 for now\n",
    "    input_to_hid = theta[0:256]\n",
    "    hid_to_class = theta[256:256+10]\n",
    "    #return a tuple instead of a model object\n",
    "    return input_to_hid, hid_to_class\n",
    "\n",
    "def model_to_theta(input_to_hid, hid_to_class):\n",
    "    return np.stack((input_to_hid, hid_to_class),axis=1)\n",
    "\n",
    "def logistic(x):\n",
    "    return 1./(1+np.exp(-x))\n",
    "\n",
    "#equivalent to log(sum(exp(A)))\n",
    "def log_sum_exp_over_rows(x):\n",
    "    #max row similar to octave max(x,[],1) returns max row\n",
    "    max_row =  np.max(x,axis=0)\n",
    "    return np.log(np.sum(np.exp(x),axis=0))\n",
    "\n",
    "A=[[1,2,3],[4,5,6]]\n",
    "test_logsumexp = log_sum_exp_over_rows(A)\n",
    "print(type(test_logsumexp))\n",
    "print(test_logsumexp.shape)\n",
    "print (test_logsumexp)\n",
    "foo = np.array([ 4.04858735,  5.04858735,  6.04858735])\n",
    "print(foo)\n",
    "#np.testing.assert_array_equal(np.array([1]),np.array([1]))\n",
    "np.testing.assert_array_equal(test_logsumexp,np.array([ 4.04858735,  5.04858735,  6.04858735]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
