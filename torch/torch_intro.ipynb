{
 "metadata": {
  "name": "",
  "signature": "sha256:576ca75242b095392eb3e71f6438e301f44bc79c3b48ae8cc49d5e2a532cf3f4"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import torch\n",
      "#do not do this.. but it runs\n",
      "\n",
      "one = torch.IntTensor(1)\n",
      "five = torch.IntTensor(5)\n",
      "\n",
      "result = one * five\n",
      "print(result)\n",
      "\n",
      "# the result is the multiplication and broadcating of 2 unitialized arrays of size 1 and 5. The result is a random result. This\n",
      "#is different everytime you run it. "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "-2.6994e+08\n",
        "-1.9911e+09\n",
        "-1.7361e+09\n",
        " 5.2165e+08\n",
        " 1.1960e+09\n",
        "[torch.IntTensor of size 5]\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import torch\n",
      "\n",
      "#have to use numpy notation to create a tensor initialized to a value, if you do IntTensor[1] this just creates\n",
      "#space for the tensor w/o values. \n",
      "\n",
      "one = torch.IntTensor([1])\n",
      "two = torch.IntTensor([2]) \n",
      "sum = one * two\n",
      "print('sum:',sum) \n",
      "\n",
      "#this wont run on colab.. back to the server...\n",
      "#type torch.cuda.FloatTensor to get this to run on the GPU\n",
      "one_gpu = torch.FloatTensor([1]).type(torch.cuda.FloatTensor)\n",
      "two_gpu = torch.FloatTensor([4]).type(torch.cuda.FloatTensor)\n",
      "\n",
      "result = one_gpu * two_gpu\n",
      "print('result:',result)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sum: \n",
        " 2\n",
        "[torch.IntTensor of size 1]\n",
        "\n",
        "result: \n",
        " 4\n",
        "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# What is autograd? Based on a module autograd which calculates the gradients based on defining a DAG using foward propagation or\n",
      "# the linear equation below. Once the graph is defined the autograd calculates the backprop iterations. \n",
      "# there are multiple components to autograd \n",
      "#\n",
      "\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "import numpy as np\n",
      "from torch.autograd import Variable\n",
      "\n",
      "#define the graph with Variables=Nodes.\n",
      "x = Variable(torch.Tensor([1]), requires_grad = True)\n",
      "w = Variable(torch.Tensor([2]), requires_grad = True)\n",
      "b = Variable(torch.Tensor([3]), requires_grad = True)\n",
      "\n",
      "#graph edges are + and *\n",
      "y = w * x + b*b\n",
      "\n",
      "#backward() calculates the derivative WRT all variables with requires_grad=True \n",
      "y.backward()\n",
      "print('x.grad: ', x.grad)\n",
      "print('w.grad:', w.grad)\n",
      "print('b.grad: ', b.grad)\n",
      "print('-----------------')\n",
      "print('x.grad.data: ', x.grad.data)\n",
      "print('w.grad.data: ', w.grad.data)\n",
      "print('b.grad.data: ', b.grad.data) #very cool 2*b is derivative of dy/db. \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "x.grad:  Variable containing:\n",
        " 2\n",
        "[torch.FloatTensor of size 1]\n",
        "\n",
        "w.grad: Variable containing:\n",
        " 1\n",
        "[torch.FloatTensor of size 1]\n",
        "\n",
        "b.grad:  Variable containing:\n",
        " 6\n",
        "[torch.FloatTensor of size 1]\n",
        "\n",
        "-----------------\n",
        "x.grad.data:  \n",
        " 2\n",
        "[torch.FloatTensor of size 1]\n",
        "\n",
        "w.grad.data:  \n",
        " 1\n",
        "[torch.FloatTensor of size 1]\n",
        "\n",
        "b.grad.data:  \n",
        " 6\n",
        "[torch.FloatTensor of size 1]\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#matrix and variable input\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}