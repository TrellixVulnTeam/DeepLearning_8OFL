{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "<h6>RNN and Gated RNN</h6>\n",
    "<p>Intro to RNNs</p>\n",
    "<p>Source: INDBA lecture Stephan Gouws and Richard Klein</p>\n",
    "<p>Slides and Video: http://www.deeplearningindaba.com/videos.html?utm_content=bufferfd4cc&utm_medium=social&utm_source=twitter.com&utm_campaign=buffer</p>\n",
    "\n",
    "<p>What a mesmerizing lecture!!!!</p>\n",
    "\n",
    "When looking at CNNs for image classificaiton what happens if given an image\n",
    "we want to match a patttern in an image, is there an efficient way to limit weights to section of image? \n",
    "Looking at idea of sequence data. RNNs and various gates and architectures. \n",
    "\n",
    "1) What is an RNN\n",
    "2) Gated ARchitectures\n",
    "\n",
    "Recurrent Models. \n",
    "<img src=\"rnn1.png\">\n",
    "We saw where we feed image into a FF network. We feed it an input and we get an output. What do we do if the image\n",
    "is 3x as wide? Do we train a new network that is 3x as large or do we feed in sequence of 3 data images? We need to be able to remember some state from previous \n",
    "time steps if we get a sequence of images. RNN intuition is we are telling someone something about state. Each time sequence\n",
    "requires some state information to be passed along. \n",
    "<img src=\"rnn2.png\">\n",
    "Long term dependencies important in language modeling. \n",
    "<img src=\"rnn3.png\">\n",
    "We have to remember the state at the beginning of the sentence using RNNs. Can do with convolution but not as efficient. \n",
    "There are different types of sequence models, a single input to many outputs, or many inputs to a singput output. \n",
    "In the one to many mapping: One input image in the case of image captioning we want NN to tell us there is a straw hat. Other type of model where we \n",
    "Get a sequence of outputs which are words in the captioning. \n",
    "<img src=\"rnn4.png\">\n",
    "<img src=\"rnn5.png\">\n",
    "In the many to one sequence example we input a sequence of pixels from an image and it outputs a predicted class!!\n",
    "The pixel sequence is only part of the image! Can also input a sentence and get a yes/no answer on classification like \n",
    "sentiment. \n",
    "<img src=\"rnn6.png\">\n",
    "In a sequence to sequence model we read all of our inputs then stop. Then we get all of our outputs. This is useful for\n",
    "translation. \n",
    "<img src=\"rnn7.png\">\n",
    "Many inputs to many outputs. Get inputs and outputs at same time. Every time step you get new input and new output. For sequence\n",
    "labeling like NER, named entity recognition. \n",
    "Each of the different sequence applicaitons. \n",
    "<img src=\"rnn8.png\">\n",
    "Classifiy the following examples, FFN vs RNN. For FFN there is now way for the model to say 192 can only calssify\n",
    "an input at one time. RNN give some input then the input updates the state inside. For an RNN we need to remember what the\n",
    "previous state was and process with new input. Every time step we need the previous state. \n",
    "\n",
    "<img src=\"rnn9.png\">\n",
    "Have Xt input coming in and have previous state which wraps around from t-1. When you unroll it you get:\n",
    "the following graph. We unroll the RNN to make it look like a Feed Forward network. \n",
    "<img src=\"rnn10.png\">\n",
    "There are 2 hiddden states, h0 is from the past. h1 is the current hidden layer. There are 2 sets of weights, one multipled by \n",
    "h0 and one by the input to get h1. You have one network and 1 set of parameters which you repeat multiple times. If you have \n",
    "a 100 items in a sequence you have to unroll 100 times. This has implications on gradient. \n",
    "The same parameters at every step. \n",
    "\n",
    "<img src=\"rnn11.png\">\n",
    "There are 2 sets of weights, Wxh and Whh which form the next state based on a multiplication wiht teh previous state\n",
    "and teh current input. The new output vector is created with the mulitplication with a 3rd set of weights. \n",
    "\n",
    "\n",
    "<img src=\"rnn12.png\">\n",
    "\n",
    "<img src=\"rnn13.png\">\n",
    "<img src=\"rnn14.png\">\n",
    "When we are running forward propagation we are inputting the entire sequence. A whole sequnece of \n",
    "pixels or a whole sequence of images. \n",
    "Equation for RNNs vs FFNs. We apply Chain rule and BP differently through the states. \n",
    "How to train? In echo state networks we initialize Wxh, Whh, Who then only train Who. BPTT, backprob through time, \n",
    "propagate error backwards through time. There are other options. Next, we train Wxx, Wxx \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tf35]",
   "language": "python",
   "name": "conda-env-tf35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
