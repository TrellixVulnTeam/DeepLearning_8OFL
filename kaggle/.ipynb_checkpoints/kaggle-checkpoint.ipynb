{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Load pickled data\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle, cv2, csv, os, time\n",
    "import numpy as np\n",
    "from numpy import newaxis\n",
    "from random import randint\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import gridspec\n",
    "%matplotlib inline\n",
    "\n",
    "import copy\n",
    "from keras.models import Sequential  #, Graph\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten, Reshape\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.utils import np_utils\n",
    "from keras.regularizers import l2\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D, AveragePooling2D\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dc/DeepLearning/kaggle\n",
      "path: /Users/dc/DeepLearning/kaggle/train/Type_2/  numFiles: 782\n",
      "path: /Users/dc/DeepLearning/kaggle/train/Type_2/  path+f: /Users/dc/DeepLearning/kaggle/train/Type_2/1.jpg\n",
      "img shape: (3264, 2448, 3)\n",
      "img_resize shape: (224, 224, 3)\n",
      "size list: 1\n",
      "path: /Users/dc/DeepLearning/kaggle/train/Type_2/  path+f: /Users/dc/DeepLearning/kaggle/train/Type_2/100.jpg\n",
      "img shape: (3264, 2448, 3)\n",
      "img_resize shape: (224, 224, 3)\n",
      "size list: 2\n",
      "path: /Users/dc/DeepLearning/kaggle/train/Type_2/  path+f: /Users/dc/DeepLearning/kaggle/train/Type_2/1001.jpg\n",
      "img shape: (4128, 3096, 3)\n",
      "img_resize shape: (224, 224, 3)\n",
      "size list: 3\n",
      "path: /Users/dc/DeepLearning/kaggle/train/Type_2/  path+f: /Users/dc/DeepLearning/kaggle/train/Type_2/1002.jpg\n",
      "img shape: (3264, 2448, 3)\n",
      "img_resize shape: (224, 224, 3)\n",
      "size list: 4\n",
      "path: /Users/dc/DeepLearning/kaggle/train/Type_2/  path+f: /Users/dc/DeepLearning/kaggle/train/Type_2/1005.jpg\n",
      "img shape: (4128, 3096, 3)\n",
      "img_resize shape: (224, 224, 3)\n",
      "size list: 5\n",
      "path: /Users/dc/DeepLearning/kaggle/train/Type_2/  path+f: /Users/dc/DeepLearning/kaggle/train/Type_2/1006.jpg\n",
      "img shape: (3096, 4128, 3)\n",
      "img_resize shape: (224, 224, 3)\n",
      "size list: 6\n",
      "path: /Users/dc/DeepLearning/kaggle/train/Type_2/  path+f: /Users/dc/DeepLearning/kaggle/train/Type_2/101.jpg\n",
      "img shape: (4128, 3096, 3)\n",
      "img_resize shape: (224, 224, 3)\n",
      "size list: 7\n",
      "path: /Users/dc/DeepLearning/kaggle/train/Type_2/  path+f: /Users/dc/DeepLearning/kaggle/train/Type_2/1010.jpg\n",
      "img shape: (3264, 2448, 3)\n",
      "img_resize shape: (224, 224, 3)\n",
      "size list: 8\n",
      "path: /Users/dc/DeepLearning/kaggle/train/Type_2/  path+f: /Users/dc/DeepLearning/kaggle/train/Type_2/1011.jpg\n",
      "img shape: (4128, 3096, 3)\n",
      "img_resize shape: (224, 224, 3)\n",
      "size list: 9\n",
      "path: /Users/dc/DeepLearning/kaggle/train/Type_2/  path+f: /Users/dc/DeepLearning/kaggle/train/Type_2/1012.jpg\n",
      "img shape: (4128, 3096, 3)\n",
      "img_resize shape: (224, 224, 3)\n",
      "size list: 10\n",
      "path: /Users/dc/DeepLearning/kaggle/train/Type_2/  path+f: /Users/dc/DeepLearning/kaggle/train/Type_2/1016.jpg\n",
      "img shape: (4128, 3096, 3)\n",
      "img_resize shape: (224, 224, 3)\n",
      "size list: 11\n",
      "path: /Users/dc/DeepLearning/kaggle/train/Type_2/  path+f: /Users/dc/DeepLearning/kaggle/train/Type_2/1017.jpg\n",
      "img shape: (4128, 3096, 3)\n",
      "img_resize shape: (224, 224, 3)\n",
      "size list: 12\n",
      "path: /Users/dc/DeepLearning/kaggle/train/Type_2/  path+f: /Users/dc/DeepLearning/kaggle/train/Type_2/1018.jpg\n",
      "img shape: (4128, 3096, 3)\n",
      "img_resize shape: (224, 224, 3)\n",
      "size list: 13\n",
      "path: /Users/dc/DeepLearning/kaggle/train/Type_2/  path+f: /Users/dc/DeepLearning/kaggle/train/Type_2/1021.jpg\n",
      "img shape: (4128, 3096, 3)\n",
      "img_resize shape: (224, 224, 3)\n",
      "size list: 14\n",
      "path: /Users/dc/DeepLearning/kaggle/train/Type_2/  path+f: /Users/dc/DeepLearning/kaggle/train/Type_2/1022.jpg\n",
      "img shape: (3264, 2448, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "current_path = os.getcwd()\n",
    "print (current_path)\n",
    "train_path1 = current_path + \"/train/Type_1/\"\n",
    "train_path2 = current_path + \"/train/Type_2/\"\n",
    "train_path3 = current_path + \"/train/Type_3/\"\n",
    "add_type1 = current_path + \"/additional_Type_1_v2/Type_1/\" \n",
    "add_type2 = current_path + \"/additional_Type_2_v2/Type_2/\" \n",
    "add_type3 = current_path + \"/additional_Type_3_v2/Type_3/\" \n",
    "\n",
    "test = current_path+\"/test/\"\n",
    "\n",
    "path_list =[]\n",
    "path_list.append(add_type1)\n",
    "path_list.append(add_type2)\n",
    "path_list.append(add_type3)\n",
    "path_list.append(train_path1)\n",
    "path_list.append(train_path2)\n",
    "path_list.append(train_path3)\n",
    "\n",
    "path_list.append(test)\n",
    "\n",
    " \n",
    "def resize_images(path,pickle_filename):\n",
    "    resize_img=[]\n",
    "    size_dict= {}\n",
    "    #for path in path_list:\n",
    "    start_time = time.time()\n",
    "    for root, dirs, files in os.walk(path, topdown=False):\n",
    "        print (\"path:\",path,' numFiles:',len(files))\n",
    "        for f in files:\n",
    "            if f !='.DS_Store':\n",
    "                print (\"path:\",path,\" path+f:\",path+f)\n",
    "                img = cv2.imread(path+f)\n",
    "                print (\"img shape:\",img.shape)\n",
    "                image_resize = resize(img, (224, 224), mode='reflect')\n",
    "                print(\"img_resize shape:\",image_resize.shape)\n",
    "                resize_img.append(image_resize)\n",
    "                print(\"size list:\",len(resize_img))                \n",
    "                size_dict[img.shape[0]]=img.shape[1]\n",
    "        print(\"dict of image dimensions:\",size_dict)\n",
    "        with open(pickle_filename,'wb') as save_file:\n",
    "            pickle.dump(resize_img,save_file)\n",
    "    end_time = time.time()\n",
    "    print(\"elapsed time:\",(end_time-start_time)/60.)\n",
    "\n",
    "#uncomment each one to run. Should run wo memory error. \n",
    "#resize_images(train_path1,'type1_resize.p')\n",
    "resize_images(train_path2,'type2resize.p')\n",
    "#resize_images(train_path3,'type3resize.p')\n",
    "#resize_images(add_type1,'type1addresize.p')\n",
    "#resize_images(test,'test.p')\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num type1 images(250): 250\n",
      "num type1 additional images(1190): 1190\n",
      "1440\n",
      "0\n",
      "num labels_1: 1440\n"
     ]
    }
   ],
   "source": [
    "img1 = []\n",
    "read_file = open('type1_resize.p', 'rb') \n",
    "imgs_type1 = pickle.load( read_file)\n",
    "img1 += imgs_type1\n",
    "print(\"num type1 images(250):\", len(imgs_type1)) #should be 250\n",
    "\n",
    "read_file = open('type1add_resize.p', 'rb') \n",
    "imgs_type1 = pickle.load( read_file)\n",
    "img1 += imgs_type1\n",
    "print('num type1 additional images(1190):',len(imgs_type1))\n",
    "\n",
    "\n",
    "print(len(img1))\n",
    "label_1 = [0]*(len(img1))\n",
    "print (label_1[0])\n",
    "print ('num labels_1:',len(label_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/Users/dc/DeepLearning/kaggle/additional_Type_2_v2/Type_2/'\n",
    "path_first='/Users/dc/DeepLearning/kaggle/first1k/'\n",
    "path_second='/Users/dc/DeepLearning/kaggle/2ndk/'\n",
    "path_third='/Users/dc/DeepLearning/kaggle/3rdk/'\n",
    "num=0\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for file in files:\n",
    "        print('moving:',file)\n",
    "        if (file != '.DS_Store'):\n",
    "            if (num < 1000):\n",
    "                os.rename(path+file,path_first+file)\n",
    "            elif ((num>1000) and (num<2000)):\n",
    "                os.rename(path+file,path_second+file)\n",
    "            else:\n",
    "                os.rename(path+file,path_third+file)\n",
    "            num+=1\n",
    "    print('num:',num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_first='/Users/dc/DeepLearning/kaggle/first1k/'\n",
    "path_second='/Users/dc/DeepLearning/kaggle/2ndk/'\n",
    "path_third='/Users/dc/DeepLearning/kaggle/3rdk/'\n",
    "\n",
    "resize_images(path_first,'type2_first.p')\n",
    "resize_images(path_second,'type2_second.p')\n",
    "resize_images(path_third,'type2_third.p')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#redo type 2. Too many files for stupid pickle format\n",
    "\n",
    "path = '/Users/dc/DeepLearning/kaggle/additional_Type_2_v2'\n",
    "first1k=[]\n",
    "second1k=[]\n",
    "third1k=[]\n",
    "for file in os.walk(path):\n",
    "    print (file)\n",
    "    img = cv2.imread(path+file)\n",
    "    image_resize = resize(img, (224, 224), mode='reflect')\n",
    "    if (num < 1000) and (file!='.DS_Store'):\n",
    "        first1k.append(image_resize)\n",
    "    else if ((num>1000) and (num<2000)):\n",
    "        second1k.append(image_resize)\n",
    "    else:\n",
    "        thirdk.append(image_resize)\n",
    "    num+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num type2_second: 1566\n",
      "num type2_first: 1000\n",
      "num type2_second: 999\n",
      "num type2_third: 1566\n",
      "label_2: 4346\n",
      "1\n",
      "num img2: 5131\n"
     ]
    }
   ],
   "source": [
    "#redo type2\n",
    "\n",
    "img2 = []\n",
    "\n",
    "read_file = open('type2resize.p', 'rb') \n",
    "imgs_type = pickle.load( read_file)\n",
    "img2 += imgs_type2\n",
    "print(\"num type2_resize:\", len(imgs_type2)) #should be 1000-1 for DS_Store\n",
    "\n",
    "\n",
    "read_file = open('type2_first.p', 'rb') \n",
    "imgs_type2 = pickle.load( read_file)\n",
    "img2 += imgs_type2\n",
    "print(\"num type2_first:\", len(imgs_type2)) #should be 1000\n",
    "\n",
    "read_file = open('type2_second.p', 'rb') \n",
    "imgs_type2 = pickle.load( read_file)\n",
    "img2 += imgs_type2\n",
    "print(\"num type2_second:\", len(imgs_type2)) #should be 999\n",
    "\n",
    "read_file = open('type2_third.p', 'rb') \n",
    "imgs_type2 = pickle.load( read_file)\n",
    "img2 += imgs_type2\n",
    "print(\"num type2_third:\", len(imgs_type2)) #should be 1566\n",
    "\n",
    "\n",
    "label_2=[1]*(781+1000+999+1566)\n",
    "print ('label_2:',len(label_2))\n",
    "print (label_2[0])\n",
    "print ('num img2:',len(img2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# redo type3 move type3 files\n",
    "path = '/Users/dc/DeepLearning/kaggle/additional_Type_3_v2/Type_3/'\n",
    "path_first='/Users/dc/DeepLearning/kaggle/first_third1k/'\n",
    "path_second='/Users/dc/DeepLearning/kaggle/third2ndk/'\n",
    "#path_third='/Users/dc/DeepLearning/kaggle/third3rdk/'\n",
    "\n",
    "num = 0\n",
    "\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for file in files:\n",
    "        print('moving:',file)\n",
    "        if (file != '.DS_Store'):\n",
    "            if (num < 1000):\n",
    "                os.rename(path+file,path_first+file)\n",
    "            elif ((num>1000) and (num<2000)):\n",
    "                os.rename(path+file,path_second+file)\n",
    "            else:\n",
    "                os.rename(path+file,path_third+file)\n",
    "            num+=1\n",
    "    print('num:',num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_first='/Users/dc/DeepLearning/kaggle/first_third1k/'\n",
    "path_second='/Users/dc/DeepLearning/kaggle/third2ndk/'\n",
    "#path_third='/Users/dc/DeepLearning/kaggle/3rdk/'\n",
    "\n",
    "resize_images(path_first,'type3_first.p')\n",
    "resize_images(path_second,'type3_second.p')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num type3_resize: 450\n",
      "num type3_first: 1000\n",
      "num type3_second: 975\n",
      "num img3: 2425\n",
      "len label_3: 2425\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "img3=[]\n",
    "\n",
    "read_file = open('type3resize.p', 'rb') \n",
    "imgs_type3 = pickle.load( read_file)\n",
    "img3 += imgs_type3\n",
    "print(\"num type3_resize:\", len(imgs_type3)) #should be \n",
    "\n",
    "\n",
    "read_file = open('type3_first.p', 'rb') \n",
    "imgs_type3 = pickle.load( read_file)\n",
    "img3 += imgs_type3\n",
    "print(\"num type3_first:\", len(imgs_type3)) #should be 1000\n",
    "\n",
    "read_file = open('type3_second.p', 'rb') \n",
    "imgs_type3 = pickle.load( read_file)\n",
    "img3 += imgs_type3\n",
    "print(\"num type3_second:\", len(imgs_type3)) #should be 975\n",
    "\n",
    "\n",
    "print('num img3:',len(img3))\n",
    "label_3 = [2]*(450+1000+975)\n",
    "print ('len label_3:', len(label_3))\n",
    "print (label_3[0])\n",
    "\n",
    "#convert after you mix them up and shuffle\n",
    "#label_3add = np_utils.to_categorical(label_3add, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8996 8211\n"
     ]
    }
   ],
   "source": [
    "img = img1+img2+img3\n",
    "label=label_1+label_2+label_3\n",
    "print(len(img), len(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.ndimage as ndi\n",
    "\n",
    "#crop test\n",
    "img = cv2.imread('/Users/dc/DeepLearning/kaggle/train/Type_1/0.jpg')\n",
    "\n",
    "height = img.shape[0]\n",
    "width = img.shape[1]\n",
    "cv2.line(img,(0,int(height/2.)),(int(width),int(height/2.0)),(255,0,0))\n",
    "cv2.line(img,(int(width/2.),0),(int(width/2.0),height),(255,0,0))\n",
    "\n",
    "trans_factor=.8 \n",
    "zoom_range=[.8,.8]\n",
    "\n",
    "\n",
    "y_offset = np.random.uniform(0,trans_factor*width)\n",
    "x_offset = np.random.uniform(0,trans_factor*height)\n",
    "\n",
    "print ('y_offset:', y_offset, \"x_offset:\", x_offset)\n",
    "\n",
    "offset = np.array([0,200])\n",
    "#center image\n",
    "#offset=np.array([10,10])\n",
    "scale_factor = np.random.uniform(zoom_range[0],zoom_range[1])\n",
    "print (scale_factor)\n",
    "crop = np.array([[scale_factor,0],[0,scale_factor]])\n",
    "\n",
    "print('image.shape before roll:',img.shape)\n",
    "img_roll = np.rollaxis(img,axis=-1, start=0)\n",
    "print('image.shape after roll:',img_roll.shape)\n",
    "#this is for the affine transform for each channel you have to roll the axis? Seems funky\n",
    "#you can use a numpy.reshape also. this is clearer and more mainstream\n",
    "\n",
    "image_channel = [ndi.interpolation.affine_transform(image_channel,\n",
    "                        crop, offset=offset, order=0, mode='nearest',\n",
    "                        cval=0.0) for image_channel in img_roll]\n",
    "image_array = np.stack(image_channel, axis=0)\n",
    "image_array = np.rollaxis(image_array, 0, 3)\n",
    "\n",
    "print ('image_array:',image_array.shape)\n",
    "#height_rs = image_array.shape[0]\n",
    "#width_rs = image_array.shape[1]\n",
    "#print(height_rs, width_rs)\n",
    "#cv2.line(image_array,(10,10),(100,100),(255,0,0))\n",
    "#cv2.line(image_array,(0,int(height_rs/2.)),(int(width_rs),int(height_rs/2.0)),(255,0,0))\n",
    "#cv2.line(image_array,(int(width_rs/2.),0),(int(width_rs/2.0),height_rs),(255,0,0))\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 1)\n",
    "ax.imshow(img)\n",
    "plt.title(\"orig\")\n",
    "ax1 = fig.add_subplot(2, 2, 2)\n",
    "ax1.imshow(image_array)\n",
    "plt.title(\"crop .8\")\n",
    "#fig.add_subplot(image_array)\n",
    "\n",
    "#plt.show()\n",
    "#problem is the shift away from center in the crop .8 image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#we can crop to produce a smaller resolution. \n",
    "import skimage\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "\n",
    "image = cv2.imread('/Users/dc/DeepLearning/kaggle/train/Type_1/0.jpg')\n",
    "height = image.shape[0]\n",
    "width = image.shape[1]\n",
    "cv2.line(image,(0,int(height/2.)),(int(width),int(height/2.0)),(255,0,0))\n",
    "cv2.line(image,(int(width/2.),0),(int(width/2.0),height),(255,0,0))\n",
    "\n",
    "\n",
    "print ('orig:',image.shape)\n",
    "image_resized = resize(image, (400, 400), mode='reflect')\n",
    "height = image_resized.shape[0]\n",
    "width = image_resized.shape[1]\n",
    "cv2.line(image_resized,(0,int(height/2.)),(int(width),int(height/2.0)),(255,0,0))\n",
    "cv2.line(image_resized,(int(width/2.),0),(int(width/2.0),height),(255,0,0))\n",
    "\n",
    "#image_downscaled = downscale_local_mean(image, (480, 640))\n",
    "print ('resized:',image_resized.shape)\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2,\n",
    "                         sharex=True, sharey=True)\n",
    "\n",
    "ax = axes.ravel()\n",
    "ax[0].imshow(image)\n",
    "ax[0].set_title(\"Original image\")\n",
    "\n",
    "ax[1].imshow(image_resized)\n",
    "ax[1].set_title(\"resized\")\n",
    "\n",
    "#ax[2].imshow(image_downscaled)\n",
    "#ax[2].set_title(\"downscaled\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "print (K.image_data_format())\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=( 15ewq0, 150,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os,random\n",
    "\n",
    "\n",
    "def move_file(source_path,dest_path):\n",
    "    \"\"\"\n",
    "    input: source path, dest path\n",
    "    output: move 20 percent files from source path to dest path\n",
    "    \"\"\"\n",
    "    list_files = os.listdir(source_path)\n",
    "    print (len(list_files))\n",
    "\n",
    "    num_moved=0\n",
    "    for x in range(1,int(.20*len(list_files))):\n",
    "        index = random.randint(1, len(list_files))\n",
    "        print(index,list_files[index])\n",
    "        source_file = source_path+list_files[index]\n",
    "        if(os.path.isfile(source_file)):\n",
    "            dest_file = dest_path+list_files[index]\n",
    "            os.rename(source_file,dest_file)\n",
    "            num_moved+=1\n",
    "\n",
    "    print (num_moved)\n",
    "\n",
    "#move_file(os.getcwd()+\"/data/train/type1/\",os.getcwd()+\"/data/valid/type1/\")\n",
    "#move_file(os.getcwd()+\"/data/train/type2/\",os.getcwd()+\"/data/valid/type2/\")\n",
    "move_file(os.getcwd()+\"/data/train/type3/\",os.getcwd()+\"/data/valid/type3/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "lab_1 = np_utils.to_categorical(label_1, 3)\n",
    "lab_2 = np_utils.to_categorical(label_2, 3)\n",
    "lab_3 = np_utils.to_categorical(label_3, 3)\n",
    "\n",
    "img_1 = np.array(img1)\n",
    "img_2 = np.array(img2)\n",
    "img_3 = np.array(img3)\n",
    "\n",
    "print (img_1.shape,lab_1.shape)\n",
    "print (img_2.shape,lab_2.shape)\n",
    "print (img_3.shape,lab_3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(img1,lab_1, test_size=.20, random_state=42)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(img2,lab_2,test_size=.20, random_state=42)\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(img3,lab_3,test_size=.20, random_state=42)\n",
    "\n",
    "X_train1 = np.array(X_train1)\n",
    "X_test1 = np.array(X_test1)\n",
    "print(type(X_train1), type(X_test1), type(y_train1), type(y_test1))\n",
    "\n",
    "X_train2 = np.array(X_train2)\n",
    "X_test2 = np.array(X_test2)\n",
    "\n",
    "X_train3 = np.array(X_train3)\n",
    "X_test3 = np.array(X_test3)\n",
    "\n",
    "\n",
    "print(X_train1.shape, X_test1.shape, y_train1.shape, y_test1.shape)\n",
    "print(X_train2.shape, X_test2.shape, y_train2.shape, y_test2.shape)\n",
    "print(X_train3.shape, X_test3.shape, y_train3.shape, y_test3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.concatenate((X_train1,X_train2,X_train3))\n",
    "X_test = np.concatenate((X_test1, X_test2, X_test3))\n",
    "y_train = np.concatenate((y_train1, y_train2, y_train3))\n",
    "y_test = np.concatenate((y_test1, y_test2, y_test3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout,Convolution2D,MaxPooling2D,Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "# number of classes\n",
    "nb_classes = 3\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols,img_ch = 224, 224, 3\n",
    "\n",
    "# number of convolutional filters to use\n",
    "nb_filter1 = 32\n",
    "nb_filter2 = 64\n",
    "nb_filter3 = 128\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, kernel_size=(3, 3),padding='same',\n",
    "                        input_shape=(img_rows,img_cols,img_ch),name='conv1'))\n",
    "model.add(Activation('relu',name='relu1'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=1,name='maxpool1'))\n",
    "model.add(Convolution2D(64, kernel_size=(3, 3),padding='same',\n",
    "                        name='conv2'))\n",
    "model.add(Activation('relu',name='relu2'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=None,name='maxpool2'))\n",
    "model.add(Convolution2D(128, kernel_size=(3, 3), padding='same',\n",
    "                        name='conv3'))\n",
    "model.add(Activation('relu',name='relu3'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=None,name='maxpool3'))\n",
    "model.add(Flatten(name='flatten'))\n",
    "model.add(Dropout(0.5,name='dropout1'))\n",
    "model.add(Dense(128, name='hidden1'))\n",
    "model.add(Activation('relu',name='relu4'))\n",
    "model.add(Dropout(0.5,name='dropout2'))\n",
    "model.add(Dense(128,  name='hidden2'))\n",
    "model.add(Activation('relu',name='relu5'))\n",
    "model.add(Dense(nb_classes, name='output'))\n",
    "model.add(Activation('softmax',name='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "nb_epoch = 1000\n",
    "batch_size=128\n",
    "\n",
    "model_name='test.chkpt'\n",
    "\n",
    "if os.path.isfile(model_name):\n",
    "    try:\n",
    "        model = load_model(model_name)\n",
    "        print('loading trained model ...')\n",
    "    except Exception as e:\n",
    "        print('Unable to load model', model_name, ':', e)\n",
    "        raise    \n",
    "\n",
    "\n",
    "adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(optimizer=adam,\n",
    "          loss='categorical_crossentropy',\n",
    "          metrics=['accuracy'])\n",
    "\n",
    "startTime = time.time()\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size, epochs=nb_epoch,\n",
    "                    verbose=2, validation_data=(X_test, y_test))\n",
    "\n",
    "endTime = time.time()\n",
    "print('elapsed secs:', (endTime - startTime)/1000.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'data/train',  # this is the target directory\n",
    "        target_size=(150, 150),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'data/valid',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(train_datagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=2000 // batch_size,\n",
    "        epochs=50,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=800 // batch_size)\n",
    "model.save_weights('first_try.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
