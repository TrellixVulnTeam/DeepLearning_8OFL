{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Load pickled data\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle, cv2, csv, os, time\n",
    "import numpy as np\n",
    "from numpy import newaxis\n",
    "from random import randint\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import gridspec\n",
    "%matplotlib inline\n",
    "from keras.models import model_from_json\n",
    "from keras.optimizers import Adam\n",
    "import copy\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten, Reshape\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.utils import np_utils\n",
    "from keras.regularizers import l2\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D, AveragePooling2D\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dc/DeepLearning/kaggle\n",
      "path: /Users/dc/DeepLearning/kaggle/additional_Type_2_v2/Type_2/  numFiles: 1\n",
      "dict of image dimensions: {}\n",
      "elapsed time: 5.289713541666667e-05\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "current_path = os.getcwd()\n",
    "print (current_path)\n",
    "train_path1 = current_path + \"/train/Type_1/\"\n",
    "train_path2 = current_path + \"/train/Type_2/\"\n",
    "train_path3 = current_path + \"/train/Type_3/\"\n",
    "add_type1 = current_path + \"/additional_Type_1_v2/Type_1/\" \n",
    "add_type2 = current_path + \"/additional_Type_2_v2/Type_2/\" \n",
    "add_type3 = current_path + \"/additional_Type_3_v2/Type_3/\" \n",
    "\n",
    "test = current_path+\"/test/\"\n",
    "\n",
    "path_list =[]\n",
    "path_list.append(add_type1)\n",
    "path_list.append(add_type2)\n",
    "path_list.append(add_type3)\n",
    "path_list.append(train_path1)\n",
    "path_list.append(train_path2)\n",
    "path_list.append(train_path3)\n",
    "\n",
    "path_list.append(test)\n",
    "\n",
    " \n",
    "def resize_images(path,pickle_filename):\n",
    "    resize_img=[]\n",
    "    size_dict= {}\n",
    "    #for path in path_list:\n",
    "    start_time = time.time()\n",
    "    for root, dirs, files in os.walk(path, topdown=False):\n",
    "        print (\"path:\",path,' numFiles:',len(files))\n",
    "        for f in files:\n",
    "            if f !='.DS_Store':\n",
    "                print (\"path:\",path,\" path+f:\",path+f)\n",
    "                img = cv2.imread(path+f)\n",
    "                print (\"img shape:\",img.shape)\n",
    "                image_resize = resize(img, (32, 32), mode='reflect')\n",
    "                print(\"img_resize shape:\",image_resize.shape)\n",
    "                resize_img.append(image_resize)\n",
    "                print(\"size list:\",len(resize_img))                \n",
    "                size_dict[img.shape[0]]=img.shape[1]\n",
    "        print(\"dict of image dimensions:\",size_dict)\n",
    "        with open(pickle_filename,'wb') as save_file:\n",
    "            pickle.dump(resize_img,save_file)\n",
    "    end_time = time.time()\n",
    "    print(\"elapsed time:\",(end_time-start_time)/60.)\n",
    "\n",
    "#uncomment each one to run. Should run wo memory error. \n",
    "#resize_images(train_path1,'type1_resize32.p')\n",
    "#resize_images(train_path2,'type2resize32.p')\n",
    "#resize_images(train_path3,'type3resize32.p')\n",
    "#resize_images(add_type1,'type1addresize32.p')\n",
    "resize_images(add_type2,'type2addresize32.p')\n",
    "#resize_images(add_type3,'type3addresize32.p')\n",
    "#resize_images(test,'test.p')\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num type1 images(250): 250\n",
      "num type1 additional images(1190): 1190\n",
      "1440\n",
      "sample label for class Type1 should be 0: 0\n",
      "num labels_1: 1440\n"
     ]
    }
   ],
   "source": [
    "img1 = []\n",
    "read_file = open('type1_resize32.p', 'rb') \n",
    "imgs_type1 = pickle.load( read_file)\n",
    "img1 += imgs_type1\n",
    "print(\"num type1 images(250):\", len(imgs_type1)) #should be 250\n",
    "\n",
    "read_file = open('type1addresize32.p', 'rb') \n",
    "imgs_type1 = pickle.load( read_file)\n",
    "img1 += imgs_type1\n",
    "print('num type1 additional images(1190):',len(imgs_type1))\n",
    "\n",
    "\n",
    "print(len(img1))\n",
    "label_1 = [0]*(len(img1))\n",
    "print ('sample label for class Type1 should be 0:',label_1[0])\n",
    "print ('num labels_1:',len(label_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "read_file = open('test.p','rb')\n",
    "imgs_test = pickle.load(read_file)\n",
    "print(len(imgs_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/Users/dc/DeepLearning/kaggle/additional_Type_2_v2/Type_2/'\n",
    "path_first='/Users/dc/DeepLearning/kaggle/first1k/'\n",
    "path_second='/Users/dc/DeepLearning/kaggle/2ndk/'\n",
    "path_third='/Users/dc/DeepLearning/kaggle/3rdk/'\n",
    "num=0\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for file in files:\n",
    "        print('moving:',file)\n",
    "        if (file != '.DS_Store'):\n",
    "            if (num < 1000):\n",
    "                os.rename(path+file,path_first+file)\n",
    "            elif ((num>1000) and (num<2000)):\n",
    "                os.rename(path+file,path_second+file)\n",
    "            else:\n",
    "                os.rename(path+file,path_third+file)\n",
    "            num+=1\n",
    "    print('num:',num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_first='/Users/dc/DeepLearning/kaggle/first1k/'\n",
    "path_second='/Users/dc/DeepLearning/kaggle/2ndk/'\n",
    "path_third='/Users/dc/DeepLearning/kaggle/3rdk/'\n",
    "\n",
    "resize_images(path_first,'type2_first.p')\n",
    "resize_images(path_second,'type2_second.p')\n",
    "resize_images(path_third,'type2_third.p')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#redo type 2. Too many files for stupid pickle format\n",
    "\n",
    "path = '/Users/dc/DeepLearning/kaggle/additional_Type_2_v2'\n",
    "first1k=[]\n",
    "second1k=[]\n",
    "third1k=[]\n",
    "for file in os.walk(path):\n",
    "    print (file)\n",
    "    img = cv2.imread(path+file)\n",
    "    image_resize = resize(img, (224, 224), mode='reflect')\n",
    "    if (num < 1000) and (file!='.DS_Store'):\n",
    "        first1k.append(image_resize)\n",
    "    else if ((num>1000) and (num<2000)):\n",
    "        second1k.append(image_resize)\n",
    "    else:\n",
    "        thirdk.append(image_resize)\n",
    "    num+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num type2_resize: 781\n",
      "num type2addresize: 0\n",
      "label_2: 4346\n",
      "sample label for Type2 should be 1: 1\n",
      "num img2: 781\n"
     ]
    }
   ],
   "source": [
    "#redo type2\n",
    "\n",
    "img2 = []\n",
    "\n",
    "read_file = open('type2resize32.p', 'rb') \n",
    "imgs_type2 = pickle.load( read_file)\n",
    "img2 += imgs_type2\n",
    "print(\"num type2_resize:\", len(imgs_type2)) #should be 1000-1 for DS_Store\n",
    "\n",
    "read_file = open('type2addresize32.p', 'rb') \n",
    "imgs_type2 = pickle.load( read_file)\n",
    "img2 += imgs_type2\n",
    "print(\"num type2addresize32:\", len(imgs_type2)) #should be 1000-1 for DS_Store\n",
    "\n",
    "\n",
    "#read_file = open('type2_first.p', 'rb') \n",
    "#imgs_type2 = pickle.load( read_file)\n",
    "#img2 += imgs_type2\n",
    "#print(\"num type2_first:\", len(imgs_type2)) #should be 1000\n",
    "\n",
    "#read_file = open('type2_second.p', 'rb') \n",
    "#imgs_type2 = pickle.load( read_file)\n",
    "#img2 += imgs_type2\n",
    "#print(\"num type2_second:\", len(imgs_type2)) #should be 999\n",
    "\n",
    "#read_file = open('type2_third.p', 'rb') \n",
    "#imgs_type2 = pickle.load( read_file)\n",
    "#img2 += imgs_type2\n",
    "#print(\"num type2_third:\", len(imgs_type2)) #should be 1566\n",
    "\n",
    "\n",
    "label_2=[1]*(781+1000+999+1566)\n",
    "print ('label_2:',len(label_2))\n",
    "print ('sample label for Type2 should be 1:',label_2[0])\n",
    "print ('num img2:',len(img2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# redo type3 move type3 files\n",
    "path = '/Users/dc/DeepLearning/kaggle/additional_Type_3_v2/Type_3/'\n",
    "path_first='/Users/dc/DeepLearning/kaggle/first_third1k/'\n",
    "path_second='/Users/dc/DeepLearning/kaggle/third2ndk/'\n",
    "#path_third='/Users/dc/DeepLearning/kaggle/third3rdk/'\n",
    "\n",
    "num = 0\n",
    "\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for file in files:\n",
    "        print('moving:',file)\n",
    "        if (file != '.DS_Store'):\n",
    "            if (num < 1000):\n",
    "                os.rename(path+file,path_first+file)\n",
    "            elif ((num>1000) and (num<2000)):\n",
    "                os.rename(path+file,path_second+file)\n",
    "            else:\n",
    "                os.rename(path+file,path_third+file)\n",
    "            num+=1\n",
    "    print('num:',num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_first='/Users/dc/DeepLearning/kaggle/first_third1k/'\n",
    "path_second='/Users/dc/DeepLearning/kaggle/third2ndk/'\n",
    "#path_third='/Users/dc/DeepLearning/kaggle/3rdk/'\n",
    "\n",
    "resize_images(path_first,'type3_first.p')\n",
    "resize_images(path_second,'type3_second.p')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num type3_resize: 450\n",
      "num type3_first: 1000\n",
      "num type3_second: 975\n",
      "num img3: 2425\n",
      "len label_3: 2425\n",
      "sample label for Type3, should be 2: 2\n"
     ]
    }
   ],
   "source": [
    "img3=[]\n",
    "\n",
    "read_file = open('type3resize.p', 'rb') \n",
    "imgs_type3 = pickle.load( read_file)\n",
    "img3 += imgs_type3\n",
    "print(\"num type3_resize:\", len(imgs_type3)) #should be \n",
    "\n",
    "\n",
    "read_file = open('type3_first.p', 'rb') \n",
    "imgs_type3 = pickle.load( read_file)\n",
    "img3 += imgs_type3\n",
    "print(\"num type3_first:\", len(imgs_type3)) #should be 1000\n",
    "\n",
    "read_file = open('type3_second.p', 'rb') \n",
    "imgs_type3 = pickle.load( read_file)\n",
    "img3 += imgs_type3\n",
    "print(\"num type3_second:\", len(imgs_type3)) #should be 975\n",
    "\n",
    "\n",
    "print('num img3:',len(img3))\n",
    "label_3 = [2]*(450+1000+975)\n",
    "print ('len label_3:', len(label_3))\n",
    "print ('sample label for Type3, should be 2:',label_3[0])\n",
    "\n",
    "#convert after you mix them up and shuffle\n",
    "#label_3add = np_utils.to_categorical(label_3add, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8211 8211\n",
      "<class 'list'> <class 'list'>\n",
      "(8211, 224, 224, 3) (8211, 3)\n"
     ]
    }
   ],
   "source": [
    "#error check\n",
    "img = img1+img2+img3\n",
    "label=label_1+label_2+label_3\n",
    "\n",
    "#save these to verify the labels match the images\n",
    "with open('img.p','wb') as save_file:\n",
    "    pickle.dump(img,save_file)\n",
    "with open('label.p','wb') as save_file:\n",
    "    pickle.dump(label,save_file)\n",
    "\n",
    "print(len(img), len(label))\n",
    "print(type(img),type(label))\n",
    "X_train = np.array(img)\n",
    "y_train = np_utils.to_categorical(label, 3)\n",
    "print(X_train.shape, y_train.shape)\n",
    "#change to 25% then split test to test and valid. \n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X_train,y_train, test_size=.25, random_state=42)\n",
    "X_test2,ytest2,Xvalid2,yvalid2 = train_test_split(X_test1,y_test2,test_size=.5,random_state=42)\n",
    "\n",
    "#normalize \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = np.array(imgs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asdf=np_utils.to_categorical(y_train,3)\n",
    "asdf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channels_last\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "print (K.image_data_format())\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=( 150, 150,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os,random\n",
    "\n",
    "\n",
    "def move_file(source_path,dest_path):\n",
    "    \"\"\"\n",
    "    input: source path, dest path\n",
    "    output: move 20 percent files from source path to dest path\n",
    "    \"\"\"\n",
    "    list_files = os.listdir(source_path)\n",
    "    print (len(list_files))\n",
    "\n",
    "    num_moved=0\n",
    "    for x in range(1,int(.20*len(list_files))):\n",
    "        index = random.randint(1, len(list_files))\n",
    "        print(index,list_files[index])\n",
    "        source_file = source_path+list_files[index]\n",
    "        if(os.path.isfile(source_file)):\n",
    "            dest_file = dest_path+list_files[index]\n",
    "            os.rename(source_file,dest_file)\n",
    "            num_moved+=1\n",
    "\n",
    "    print (num_moved)\n",
    "\n",
    "#move_file(os.getcwd()+\"/data/train/type1/\",os.getcwd()+\"/data/valid/type1/\")\n",
    "#move_file(os.getcwd()+\"/data/train/type2/\",os.getcwd()+\"/data/valid/type2/\")\n",
    "move_file(os.getcwd()+\"/data/train/type3/\",os.getcwd()+\"/data/valid/type3/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv2D)               (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "relu1 (Activation)           (None, 224, 224, 32)      0         \n",
      "_________________________________________________________________\n",
      "maxpool1 (MaxPooling2D)      (None, 223, 223, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 223, 223, 64)      18496     \n",
      "_________________________________________________________________\n",
      "relu2 (Activation)           (None, 223, 223, 64)      0         \n",
      "_________________________________________________________________\n",
      "maxpool2 (MaxPooling2D)      (None, 111, 111, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 111, 111, 128)     73856     \n",
      "_________________________________________________________________\n",
      "relu3 (Activation)           (None, 111, 111, 128)     0         \n",
      "_________________________________________________________________\n",
      "maxpool3 (MaxPooling2D)      (None, 55, 55, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 387200)            0         \n",
      "_________________________________________________________________\n",
      "dropout1 (Dropout)           (None, 387200)            0         \n",
      "_________________________________________________________________\n",
      "hidden1 (Dense)              (None, 128)               49561728  \n",
      "_________________________________________________________________\n",
      "relu4 (Activation)           (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout2 (Dropout)           (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "relu5 (Activation)           (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 3)                 387       \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 49,671,875\n",
      "Trainable params: 49,671,875\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout,Convolution2D,MaxPooling2D,Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "# number of classes\n",
    "nb_classes = 3\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols,img_ch = 224, 224, 3\n",
    "\n",
    "# number of convolutional filters to use\n",
    "nb_filter1 = 32\n",
    "nb_filter2 = 64\n",
    "nb_filter3 = 128\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, kernel_size=(3, 3),padding='same',\n",
    "                        input_shape=(img_rows,img_cols,img_ch),name='conv1'))\n",
    "model.add(Activation('relu',name='relu1'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=1,name='maxpool1'))\n",
    "model.add(Convolution2D(64, kernel_size=(3, 3),padding='same',\n",
    "                        name='conv2'))\n",
    "model.add(Activation('relu',name='relu2'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=None,name='maxpool2'))\n",
    "model.add(Convolution2D(128, kernel_size=(3, 3), padding='same',\n",
    "                        name='conv3'))\n",
    "model.add(Activation('relu',name='relu3'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=None,name='maxpool3'))\n",
    "model.add(Flatten(name='flatten'))\n",
    "model.add(Dropout(0.5,name='dropout1'))\n",
    "model.add(Dense(128, name='hidden1'))\n",
    "model.add(Activation('relu',name='relu4'))\n",
    "model.add(Dropout(0.5,name='dropout2'))\n",
    "model.add(Dense(128,  name='hidden2'))\n",
    "model.add(Activation('relu',name='relu5'))\n",
    "model.add(Dense(nb_classes, name='output'))\n",
    "model.add(Activation('softmax',name='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6568 samples, validate on 1643 samples\n",
      "Epoch 1/200\n",
      "52s - loss: 1.0027 - acc: 0.5228 - val_loss: 0.9826 - val_acc: 0.5204\n",
      "Epoch 2/200\n",
      "45s - loss: 0.9677 - acc: 0.5344 - val_loss: 0.9626 - val_acc: 0.5356\n",
      "Epoch 3/200\n",
      "45s - loss: 0.9429 - acc: 0.5445 - val_loss: 0.9527 - val_acc: 0.5350\n",
      "Epoch 4/200\n",
      "46s - loss: 0.9226 - acc: 0.5513 - val_loss: 0.9193 - val_acc: 0.5563\n",
      "Epoch 5/200\n",
      "46s - loss: 0.8891 - acc: 0.5690 - val_loss: 0.9050 - val_acc: 0.5624\n",
      "Epoch 6/200\n",
      "46s - loss: 0.8601 - acc: 0.5901 - val_loss: 0.8937 - val_acc: 0.5624\n",
      "Epoch 7/200\n",
      "46s - loss: 0.8310 - acc: 0.5968 - val_loss: 0.8838 - val_acc: 0.5703\n",
      "Epoch 8/200\n",
      "50s - loss: 0.7958 - acc: 0.6128 - val_loss: 0.8616 - val_acc: 0.5922\n",
      "Epoch 9/200\n",
      "47s - loss: 0.7564 - acc: 0.6465 - val_loss: 0.8714 - val_acc: 0.5989\n",
      "Epoch 10/200\n",
      "47s - loss: 0.7166 - acc: 0.6606 - val_loss: 0.8781 - val_acc: 0.5879\n",
      "Epoch 11/200\n",
      "47s - loss: 0.6751 - acc: 0.6912 - val_loss: 0.9082 - val_acc: 0.6032\n",
      "Epoch 12/200\n",
      "47s - loss: 0.6253 - acc: 0.7170 - val_loss: 0.9081 - val_acc: 0.5995\n",
      "Epoch 13/200\n",
      "47s - loss: 0.5824 - acc: 0.7425 - val_loss: 0.9451 - val_acc: 0.6032\n",
      "Epoch 14/200\n",
      "47s - loss: 0.5394 - acc: 0.7649 - val_loss: 0.9611 - val_acc: 0.6056\n",
      "Epoch 15/200\n",
      "47s - loss: 0.5021 - acc: 0.7832 - val_loss: 1.0114 - val_acc: 0.6129\n",
      "Epoch 16/200\n",
      "47s - loss: 0.4785 - acc: 0.7897 - val_loss: 0.9507 - val_acc: 0.6275\n",
      "Epoch 17/200\n",
      "47s - loss: 0.4281 - acc: 0.8130 - val_loss: 1.0257 - val_acc: 0.6220\n",
      "Epoch 18/200\n",
      "47s - loss: 0.3931 - acc: 0.8377 - val_loss: 1.1031 - val_acc: 0.6233\n",
      "Epoch 19/200\n",
      "47s - loss: 0.3742 - acc: 0.8397 - val_loss: 1.1318 - val_acc: 0.6147\n",
      "Epoch 20/200\n",
      "47s - loss: 0.3369 - acc: 0.8611 - val_loss: 1.2047 - val_acc: 0.6159\n",
      "Epoch 21/200\n",
      "47s - loss: 0.3151 - acc: 0.8688 - val_loss: 1.2981 - val_acc: 0.6056\n",
      "Epoch 22/200\n",
      "47s - loss: 0.2843 - acc: 0.8787 - val_loss: 1.3022 - val_acc: 0.6251\n",
      "Epoch 23/200\n",
      "47s - loss: 0.2623 - acc: 0.8911 - val_loss: 1.3857 - val_acc: 0.6208\n",
      "Epoch 24/200\n",
      "47s - loss: 0.2363 - acc: 0.9056 - val_loss: 1.4000 - val_acc: 0.6184\n",
      "Epoch 25/200\n",
      "47s - loss: 0.2359 - acc: 0.9048 - val_loss: 1.5792 - val_acc: 0.6141\n",
      "Epoch 26/200\n",
      "47s - loss: 0.2169 - acc: 0.9137 - val_loss: 1.3850 - val_acc: 0.6141\n",
      "Epoch 27/200\n",
      "47s - loss: 0.2039 - acc: 0.9172 - val_loss: 1.5610 - val_acc: 0.6202\n",
      "Epoch 28/200\n",
      "47s - loss: 0.1877 - acc: 0.9265 - val_loss: 1.6580 - val_acc: 0.6233\n",
      "Epoch 29/200\n",
      "47s - loss: 0.1881 - acc: 0.9233 - val_loss: 1.4221 - val_acc: 0.6275\n",
      "Epoch 30/200\n",
      "47s - loss: 0.1807 - acc: 0.9294 - val_loss: 1.7288 - val_acc: 0.6245\n",
      "Epoch 31/200\n",
      "47s - loss: 0.1752 - acc: 0.9316 - val_loss: 1.5772 - val_acc: 0.6111\n",
      "Epoch 32/200\n",
      "47s - loss: 0.1606 - acc: 0.9333 - val_loss: 1.6295 - val_acc: 0.6178\n",
      "Epoch 33/200\n",
      "47s - loss: 0.1555 - acc: 0.9379 - val_loss: 1.6370 - val_acc: 0.6293\n",
      "Epoch 34/200\n",
      "47s - loss: 0.1385 - acc: 0.9469 - val_loss: 1.6568 - val_acc: 0.6275\n",
      "Epoch 35/200\n",
      "47s - loss: 0.1472 - acc: 0.9385 - val_loss: 1.7889 - val_acc: 0.6166\n",
      "Epoch 36/200\n",
      "47s - loss: 0.1414 - acc: 0.9444 - val_loss: 1.8811 - val_acc: 0.6233\n",
      "Epoch 37/200\n",
      "47s - loss: 0.1317 - acc: 0.9473 - val_loss: 1.8158 - val_acc: 0.6129\n",
      "Epoch 38/200\n",
      "47s - loss: 0.1279 - acc: 0.9511 - val_loss: 1.9027 - val_acc: 0.6111\n",
      "Epoch 39/200\n",
      "47s - loss: 0.1218 - acc: 0.9523 - val_loss: 1.8635 - val_acc: 0.6226\n",
      "Epoch 40/200\n",
      "47s - loss: 0.1172 - acc: 0.9558 - val_loss: 1.8257 - val_acc: 0.6287\n",
      "Epoch 41/200\n",
      "47s - loss: 0.1080 - acc: 0.9587 - val_loss: 2.0087 - val_acc: 0.6251\n",
      "Epoch 42/200\n",
      "47s - loss: 0.1104 - acc: 0.9548 - val_loss: 2.0215 - val_acc: 0.6269\n",
      "Epoch 43/200\n",
      "47s - loss: 0.1104 - acc: 0.9587 - val_loss: 1.9674 - val_acc: 0.6293\n",
      "Epoch 44/200\n",
      "47s - loss: 0.1082 - acc: 0.9566 - val_loss: 2.0898 - val_acc: 0.6159\n",
      "Epoch 45/200\n",
      "47s - loss: 0.1058 - acc: 0.9583 - val_loss: 2.1142 - val_acc: 0.6379\n",
      "Epoch 46/200\n",
      "47s - loss: 0.1104 - acc: 0.9563 - val_loss: 1.9802 - val_acc: 0.6336\n",
      "Epoch 47/200\n",
      "47s - loss: 0.1024 - acc: 0.9601 - val_loss: 2.0241 - val_acc: 0.6275\n",
      "Epoch 48/200\n",
      "47s - loss: 0.0945 - acc: 0.9621 - val_loss: 2.1827 - val_acc: 0.6245\n",
      "Epoch 49/200\n",
      "47s - loss: 0.0974 - acc: 0.9612 - val_loss: 2.1269 - val_acc: 0.6239\n",
      "Epoch 50/200\n",
      "47s - loss: 0.0981 - acc: 0.9615 - val_loss: 2.0749 - val_acc: 0.6312\n",
      "Epoch 51/200\n",
      "47s - loss: 0.0975 - acc: 0.9604 - val_loss: 2.0051 - val_acc: 0.6208\n",
      "Epoch 52/200\n",
      "47s - loss: 0.0845 - acc: 0.9653 - val_loss: 1.9693 - val_acc: 0.6293\n",
      "Epoch 53/200\n",
      "47s - loss: 0.0857 - acc: 0.9654 - val_loss: 2.1876 - val_acc: 0.6099\n",
      "Epoch 54/200\n",
      "47s - loss: 0.0843 - acc: 0.9667 - val_loss: 2.1865 - val_acc: 0.6220\n",
      "Epoch 55/200\n",
      "47s - loss: 0.0827 - acc: 0.9657 - val_loss: 2.2510 - val_acc: 0.6239\n",
      "Epoch 56/200\n",
      "47s - loss: 0.0862 - acc: 0.9651 - val_loss: 2.2410 - val_acc: 0.6281\n",
      "Epoch 57/200\n",
      "47s - loss: 0.0808 - acc: 0.9706 - val_loss: 2.3415 - val_acc: 0.6263\n",
      "Epoch 58/200\n",
      "47s - loss: 0.0800 - acc: 0.9688 - val_loss: 2.2287 - val_acc: 0.6245\n",
      "Epoch 59/200\n",
      "47s - loss: 0.0888 - acc: 0.9673 - val_loss: 2.2035 - val_acc: 0.6245\n",
      "Epoch 60/200\n",
      "47s - loss: 0.0842 - acc: 0.9660 - val_loss: 2.1901 - val_acc: 0.6184\n",
      "Epoch 61/200\n",
      "47s - loss: 0.0791 - acc: 0.9695 - val_loss: 2.2909 - val_acc: 0.6196\n",
      "Epoch 62/200\n",
      "47s - loss: 0.0771 - acc: 0.9699 - val_loss: 2.3226 - val_acc: 0.6293\n",
      "Epoch 63/200\n",
      "47s - loss: 0.0680 - acc: 0.9753 - val_loss: 2.3465 - val_acc: 0.6318\n",
      "Epoch 64/200\n",
      "47s - loss: 0.0712 - acc: 0.9714 - val_loss: 2.3238 - val_acc: 0.6312\n",
      "Epoch 65/200\n",
      "47s - loss: 0.0722 - acc: 0.9705 - val_loss: 2.4225 - val_acc: 0.6397\n",
      "Epoch 66/200\n",
      "47s - loss: 0.0647 - acc: 0.9744 - val_loss: 2.4521 - val_acc: 0.6147\n",
      "Epoch 67/200\n",
      "47s - loss: 0.0794 - acc: 0.9677 - val_loss: 2.3028 - val_acc: 0.6269\n",
      "Epoch 68/200\n",
      "47s - loss: 0.0736 - acc: 0.9721 - val_loss: 2.4102 - val_acc: 0.6293\n",
      "Epoch 69/200\n",
      "47s - loss: 0.0717 - acc: 0.9726 - val_loss: 2.3072 - val_acc: 0.6354\n",
      "Epoch 70/200\n",
      "47s - loss: 0.0645 - acc: 0.9746 - val_loss: 2.2920 - val_acc: 0.6275\n",
      "Epoch 71/200\n",
      "47s - loss: 0.0654 - acc: 0.9759 - val_loss: 2.2925 - val_acc: 0.6269\n",
      "Epoch 72/200\n",
      "46s - loss: 0.0696 - acc: 0.9712 - val_loss: 2.2927 - val_acc: 0.6287\n",
      "Epoch 73/200\n",
      "47s - loss: 0.0621 - acc: 0.9773 - val_loss: 2.5539 - val_acc: 0.6239\n",
      "Epoch 74/200\n",
      "47s - loss: 0.0599 - acc: 0.9759 - val_loss: 2.3245 - val_acc: 0.6336\n",
      "Epoch 75/200\n",
      "47s - loss: 0.0576 - acc: 0.9796 - val_loss: 2.3463 - val_acc: 0.6287\n",
      "Epoch 76/200\n",
      "47s - loss: 0.0651 - acc: 0.9750 - val_loss: 2.4969 - val_acc: 0.6306\n",
      "Epoch 77/200\n",
      "47s - loss: 0.0606 - acc: 0.9746 - val_loss: 2.2392 - val_acc: 0.6360\n",
      "Epoch 78/200\n",
      "47s - loss: 0.0645 - acc: 0.9770 - val_loss: 2.3767 - val_acc: 0.6379\n",
      "Epoch 79/200\n",
      "47s - loss: 0.0561 - acc: 0.9776 - val_loss: 2.5975 - val_acc: 0.6342\n",
      "Epoch 80/200\n",
      "47s - loss: 0.0574 - acc: 0.9787 - val_loss: 2.3101 - val_acc: 0.6263\n",
      "Epoch 81/200\n",
      "46s - loss: 0.0585 - acc: 0.9759 - val_loss: 2.4194 - val_acc: 0.6385\n",
      "Epoch 82/200\n",
      "46s - loss: 0.0597 - acc: 0.9767 - val_loss: 2.3536 - val_acc: 0.6312\n",
      "Epoch 83/200\n",
      "46s - loss: 0.0532 - acc: 0.9791 - val_loss: 2.3462 - val_acc: 0.6433\n",
      "Epoch 84/200\n",
      "47s - loss: 0.0517 - acc: 0.9807 - val_loss: 2.4862 - val_acc: 0.6233\n",
      "Epoch 85/200\n",
      "47s - loss: 0.0572 - acc: 0.9772 - val_loss: 2.5633 - val_acc: 0.6293\n",
      "Epoch 86/200\n",
      "47s - loss: 0.0662 - acc: 0.9759 - val_loss: 2.4205 - val_acc: 0.6324\n",
      "Epoch 87/200\n",
      "47s - loss: 0.0593 - acc: 0.9781 - val_loss: 2.4368 - val_acc: 0.6257\n",
      "Epoch 88/200\n",
      "47s - loss: 0.0544 - acc: 0.9813 - val_loss: 2.5308 - val_acc: 0.6269\n",
      "Epoch 89/200\n",
      "47s - loss: 0.0533 - acc: 0.9802 - val_loss: 2.5245 - val_acc: 0.6287\n",
      "Epoch 90/200\n",
      "47s - loss: 0.0570 - acc: 0.9781 - val_loss: 2.4312 - val_acc: 0.6275\n",
      "Epoch 91/200\n",
      "47s - loss: 0.0464 - acc: 0.9829 - val_loss: 2.6453 - val_acc: 0.6366\n",
      "Epoch 92/200\n",
      "47s - loss: 0.0564 - acc: 0.9785 - val_loss: 2.4615 - val_acc: 0.6391\n",
      "Epoch 93/200\n",
      "47s - loss: 0.0437 - acc: 0.9819 - val_loss: 2.6251 - val_acc: 0.6226\n",
      "Epoch 94/200\n",
      "46s - loss: 0.0455 - acc: 0.9828 - val_loss: 2.6388 - val_acc: 0.6360\n",
      "Epoch 95/200\n",
      "47s - loss: 0.0546 - acc: 0.9796 - val_loss: 2.6631 - val_acc: 0.6379\n",
      "Epoch 96/200\n",
      "47s - loss: 0.0450 - acc: 0.9819 - val_loss: 2.6375 - val_acc: 0.6385\n",
      "Epoch 97/200\n",
      "47s - loss: 0.0476 - acc: 0.9822 - val_loss: 2.7445 - val_acc: 0.6324\n",
      "Epoch 98/200\n",
      "47s - loss: 0.0489 - acc: 0.9833 - val_loss: 2.5626 - val_acc: 0.6269\n",
      "Epoch 99/200\n",
      "47s - loss: 0.0531 - acc: 0.9794 - val_loss: 2.4871 - val_acc: 0.6281\n",
      "Epoch 100/200\n",
      "47s - loss: 0.0466 - acc: 0.9822 - val_loss: 2.5895 - val_acc: 0.6263\n",
      "Epoch 101/200\n",
      "47s - loss: 0.0485 - acc: 0.9804 - val_loss: 2.6427 - val_acc: 0.6330\n",
      "Epoch 102/200\n",
      "47s - loss: 0.0444 - acc: 0.9845 - val_loss: 2.6056 - val_acc: 0.6318\n",
      "Epoch 103/200\n",
      "46s - loss: 0.0467 - acc: 0.9816 - val_loss: 2.4320 - val_acc: 0.6293\n",
      "Epoch 104/200\n",
      "47s - loss: 0.0487 - acc: 0.9833 - val_loss: 2.5628 - val_acc: 0.6275\n",
      "Epoch 105/200\n",
      "47s - loss: 0.0475 - acc: 0.9836 - val_loss: 2.4552 - val_acc: 0.6348\n",
      "Epoch 106/200\n",
      "47s - loss: 0.0397 - acc: 0.9864 - val_loss: 2.7363 - val_acc: 0.6336\n",
      "Epoch 107/200\n",
      "47s - loss: 0.0426 - acc: 0.9833 - val_loss: 2.7149 - val_acc: 0.6324\n",
      "Epoch 108/200\n",
      "47s - loss: 0.0458 - acc: 0.9817 - val_loss: 2.5795 - val_acc: 0.6324\n",
      "Epoch 109/200\n",
      "46s - loss: 0.0419 - acc: 0.9845 - val_loss: 2.8969 - val_acc: 0.6372\n",
      "Epoch 110/200\n",
      "46s - loss: 0.0455 - acc: 0.9814 - val_loss: 2.6696 - val_acc: 0.6397\n",
      "Epoch 111/200\n",
      "47s - loss: 0.0450 - acc: 0.9834 - val_loss: 2.6230 - val_acc: 0.6324\n",
      "Epoch 112/200\n",
      "46s - loss: 0.0437 - acc: 0.9833 - val_loss: 2.6684 - val_acc: 0.6385\n",
      "Epoch 113/200\n",
      "46s - loss: 0.0499 - acc: 0.9822 - val_loss: 2.5135 - val_acc: 0.6275\n",
      "Epoch 114/200\n",
      "46s - loss: 0.0424 - acc: 0.9864 - val_loss: 2.8074 - val_acc: 0.6360\n",
      "Epoch 115/200\n",
      "46s - loss: 0.0438 - acc: 0.9839 - val_loss: 2.5683 - val_acc: 0.6379\n",
      "Epoch 116/200\n",
      "47s - loss: 0.0449 - acc: 0.9837 - val_loss: 2.7491 - val_acc: 0.6336\n",
      "Epoch 117/200\n",
      "47s - loss: 0.0475 - acc: 0.9825 - val_loss: 2.5045 - val_acc: 0.6342\n",
      "Epoch 118/200\n",
      "46s - loss: 0.0453 - acc: 0.9814 - val_loss: 2.4385 - val_acc: 0.6318\n",
      "Epoch 119/200\n",
      "47s - loss: 0.0395 - acc: 0.9848 - val_loss: 2.5787 - val_acc: 0.6269\n",
      "Epoch 120/200\n",
      "46s - loss: 0.0368 - acc: 0.9866 - val_loss: 2.7826 - val_acc: 0.6397\n",
      "Epoch 121/200\n",
      "47s - loss: 0.0423 - acc: 0.9843 - val_loss: 2.8221 - val_acc: 0.6293\n",
      "Epoch 122/200\n",
      "47s - loss: 0.0425 - acc: 0.9851 - val_loss: 2.5809 - val_acc: 0.6354\n",
      "Epoch 123/200\n",
      "46s - loss: 0.0386 - acc: 0.9852 - val_loss: 2.6610 - val_acc: 0.6263\n",
      "Epoch 124/200\n",
      "47s - loss: 0.0394 - acc: 0.9837 - val_loss: 2.7264 - val_acc: 0.6336\n",
      "Epoch 125/200\n",
      "46s - loss: 0.0369 - acc: 0.9864 - val_loss: 2.6302 - val_acc: 0.6318\n",
      "Epoch 126/200\n",
      "46s - loss: 0.0372 - acc: 0.9855 - val_loss: 2.9385 - val_acc: 0.6245\n",
      "Epoch 127/200\n",
      "47s - loss: 0.0365 - acc: 0.9861 - val_loss: 2.6840 - val_acc: 0.6348\n",
      "Epoch 128/200\n",
      "46s - loss: 0.0364 - acc: 0.9849 - val_loss: 2.8554 - val_acc: 0.6312\n",
      "Epoch 129/200\n",
      "47s - loss: 0.0367 - acc: 0.9861 - val_loss: 2.8069 - val_acc: 0.6299\n",
      "Epoch 130/200\n",
      "47s - loss: 0.0394 - acc: 0.9866 - val_loss: 2.8401 - val_acc: 0.6348\n",
      "Epoch 131/200\n",
      "46s - loss: 0.0364 - acc: 0.9880 - val_loss: 2.8195 - val_acc: 0.6360\n",
      "Epoch 132/200\n",
      "47s - loss: 0.0393 - acc: 0.9863 - val_loss: 2.6994 - val_acc: 0.6403\n",
      "Epoch 133/200\n",
      "47s - loss: 0.0417 - acc: 0.9834 - val_loss: 2.6114 - val_acc: 0.6360\n",
      "Epoch 134/200\n",
      "46s - loss: 0.0346 - acc: 0.9878 - val_loss: 2.8268 - val_acc: 0.6360\n",
      "Epoch 135/200\n",
      "47s - loss: 0.0374 - acc: 0.9872 - val_loss: 2.7749 - val_acc: 0.6446\n",
      "Epoch 136/200\n",
      "47s - loss: 0.0422 - acc: 0.9849 - val_loss: 2.6410 - val_acc: 0.6336\n",
      "Epoch 137/200\n",
      "47s - loss: 0.0329 - acc: 0.9866 - val_loss: 2.4796 - val_acc: 0.6312\n",
      "Epoch 138/200\n",
      "47s - loss: 0.0369 - acc: 0.9861 - val_loss: 2.5860 - val_acc: 0.6391\n",
      "Epoch 139/200\n",
      "46s - loss: 0.0302 - acc: 0.9904 - val_loss: 2.6945 - val_acc: 0.6348\n",
      "Epoch 140/200\n",
      "47s - loss: 0.0343 - acc: 0.9877 - val_loss: 2.7162 - val_acc: 0.6391\n",
      "Epoch 141/200\n",
      "47s - loss: 0.0350 - acc: 0.9877 - val_loss: 2.7989 - val_acc: 0.6354\n",
      "Epoch 142/200\n",
      "47s - loss: 0.0420 - acc: 0.9836 - val_loss: 2.6786 - val_acc: 0.6354\n",
      "Epoch 143/200\n",
      "47s - loss: 0.0334 - acc: 0.9883 - val_loss: 2.7617 - val_acc: 0.6372\n",
      "Epoch 144/200\n",
      "47s - loss: 0.0309 - acc: 0.9880 - val_loss: 2.8705 - val_acc: 0.6452\n",
      "Epoch 145/200\n",
      "47s - loss: 0.0325 - acc: 0.9863 - val_loss: 2.7430 - val_acc: 0.6324\n",
      "Epoch 146/200\n",
      "46s - loss: 0.0263 - acc: 0.9910 - val_loss: 3.0184 - val_acc: 0.6391\n",
      "Epoch 147/200\n",
      "46s - loss: 0.0360 - acc: 0.9881 - val_loss: 2.7175 - val_acc: 0.6342\n",
      "Epoch 148/200\n",
      "47s - loss: 0.0329 - acc: 0.9866 - val_loss: 2.8162 - val_acc: 0.6269\n",
      "Epoch 149/200\n",
      "47s - loss: 0.0272 - acc: 0.9907 - val_loss: 2.9925 - val_acc: 0.6385\n",
      "Epoch 150/200\n",
      "47s - loss: 0.0344 - acc: 0.9872 - val_loss: 2.8218 - val_acc: 0.6403\n",
      "Epoch 151/200\n",
      "47s - loss: 0.0295 - acc: 0.9887 - val_loss: 2.7463 - val_acc: 0.6324\n",
      "Epoch 152/200\n",
      "47s - loss: 0.0349 - acc: 0.9875 - val_loss: 2.7093 - val_acc: 0.6275\n",
      "Epoch 153/200\n",
      "46s - loss: 0.0313 - acc: 0.9881 - val_loss: 2.8207 - val_acc: 0.6312\n",
      "Epoch 154/200\n",
      "46s - loss: 0.0275 - acc: 0.9893 - val_loss: 2.9485 - val_acc: 0.6269\n",
      "Epoch 155/200\n",
      "47s - loss: 0.0290 - acc: 0.9892 - val_loss: 3.0036 - val_acc: 0.6372\n",
      "Epoch 156/200\n",
      "47s - loss: 0.0287 - acc: 0.9887 - val_loss: 2.9659 - val_acc: 0.6281\n",
      "Epoch 157/200\n",
      "46s - loss: 0.0363 - acc: 0.9875 - val_loss: 2.7901 - val_acc: 0.6391\n",
      "Epoch 158/200\n",
      "47s - loss: 0.0374 - acc: 0.9857 - val_loss: 2.8221 - val_acc: 0.6336\n",
      "Epoch 159/200\n",
      "47s - loss: 0.0342 - acc: 0.9896 - val_loss: 2.8736 - val_acc: 0.6366\n",
      "Epoch 160/200\n",
      "46s - loss: 0.0338 - acc: 0.9866 - val_loss: 2.9486 - val_acc: 0.6372\n",
      "Epoch 161/200\n",
      "47s - loss: 0.0290 - acc: 0.9886 - val_loss: 2.7411 - val_acc: 0.6342\n",
      "Epoch 162/200\n",
      "47s - loss: 0.0319 - acc: 0.9877 - val_loss: 2.6788 - val_acc: 0.6330\n",
      "Epoch 163/200\n",
      "47s - loss: 0.0319 - acc: 0.9892 - val_loss: 2.8638 - val_acc: 0.6397\n",
      "Epoch 164/200\n",
      "47s - loss: 0.0271 - acc: 0.9896 - val_loss: 2.7451 - val_acc: 0.6360\n",
      "Epoch 165/200\n",
      "47s - loss: 0.0282 - acc: 0.9884 - val_loss: 2.8168 - val_acc: 0.6366\n",
      "Epoch 166/200\n",
      "47s - loss: 0.0321 - acc: 0.9881 - val_loss: 2.7112 - val_acc: 0.6372\n",
      "Epoch 167/200\n",
      "47s - loss: 0.0325 - acc: 0.9875 - val_loss: 2.7694 - val_acc: 0.6385\n",
      "Epoch 168/200\n",
      "47s - loss: 0.0317 - acc: 0.9889 - val_loss: 2.8322 - val_acc: 0.6360\n",
      "Epoch 169/200\n",
      "47s - loss: 0.0288 - acc: 0.9904 - val_loss: 2.8371 - val_acc: 0.6385\n",
      "Epoch 170/200\n",
      "47s - loss: 0.0306 - acc: 0.9875 - val_loss: 2.6744 - val_acc: 0.6342\n",
      "Epoch 171/200\n",
      "47s - loss: 0.0374 - acc: 0.9872 - val_loss: 2.9356 - val_acc: 0.6403\n",
      "Epoch 172/200\n",
      "47s - loss: 0.0322 - acc: 0.9887 - val_loss: 2.7020 - val_acc: 0.6439\n",
      "Epoch 173/200\n",
      "47s - loss: 0.0283 - acc: 0.9901 - val_loss: 2.6931 - val_acc: 0.6409\n",
      "Epoch 174/200\n",
      "47s - loss: 0.0261 - acc: 0.9907 - val_loss: 2.8857 - val_acc: 0.6360\n",
      "Epoch 175/200\n",
      "46s - loss: 0.0224 - acc: 0.9927 - val_loss: 2.8998 - val_acc: 0.6372\n",
      "Epoch 176/200\n",
      "47s - loss: 0.0268 - acc: 0.9900 - val_loss: 2.6778 - val_acc: 0.6348\n",
      "Epoch 177/200\n",
      "47s - loss: 0.0305 - acc: 0.9892 - val_loss: 2.8138 - val_acc: 0.6287\n",
      "Epoch 178/200\n",
      "47s - loss: 0.0279 - acc: 0.9915 - val_loss: 2.7086 - val_acc: 0.6324\n",
      "Epoch 179/200\n",
      "47s - loss: 0.0242 - acc: 0.9906 - val_loss: 2.9727 - val_acc: 0.6306\n",
      "Epoch 180/200\n",
      "47s - loss: 0.0223 - acc: 0.9927 - val_loss: 2.9883 - val_acc: 0.6318\n",
      "Epoch 181/200\n",
      "47s - loss: 0.0329 - acc: 0.9875 - val_loss: 3.0144 - val_acc: 0.6336\n",
      "Epoch 182/200\n",
      "47s - loss: 0.0347 - acc: 0.9875 - val_loss: 2.8828 - val_acc: 0.6403\n",
      "Epoch 183/200\n",
      "47s - loss: 0.0278 - acc: 0.9890 - val_loss: 3.0825 - val_acc: 0.6336\n",
      "Epoch 184/200\n",
      "47s - loss: 0.0272 - acc: 0.9900 - val_loss: 2.9696 - val_acc: 0.6306\n",
      "Epoch 185/200\n",
      "47s - loss: 0.0277 - acc: 0.9900 - val_loss: 2.9630 - val_acc: 0.6299\n",
      "Epoch 186/200\n",
      "47s - loss: 0.0221 - acc: 0.9922 - val_loss: 2.9983 - val_acc: 0.6251\n",
      "Epoch 187/200\n",
      "47s - loss: 0.0308 - acc: 0.9886 - val_loss: 3.1083 - val_acc: 0.6287\n",
      "Epoch 188/200\n",
      "47s - loss: 0.0271 - acc: 0.9895 - val_loss: 2.8765 - val_acc: 0.6306\n",
      "Epoch 189/200\n",
      "47s - loss: 0.0243 - acc: 0.9912 - val_loss: 2.7430 - val_acc: 0.6330\n",
      "Epoch 190/200\n",
      "46s - loss: 0.0287 - acc: 0.9895 - val_loss: 2.8933 - val_acc: 0.6372\n",
      "Epoch 191/200\n",
      "47s - loss: 0.0270 - acc: 0.9910 - val_loss: 2.8807 - val_acc: 0.6318\n",
      "Epoch 192/200\n",
      "47s - loss: 0.0340 - acc: 0.9884 - val_loss: 2.9002 - val_acc: 0.6324\n",
      "Epoch 193/200\n",
      "47s - loss: 0.0251 - acc: 0.9910 - val_loss: 3.0426 - val_acc: 0.6293\n",
      "Epoch 194/200\n",
      "47s - loss: 0.0181 - acc: 0.9938 - val_loss: 3.0166 - val_acc: 0.6360\n",
      "Epoch 195/200\n",
      "47s - loss: 0.0278 - acc: 0.9895 - val_loss: 2.7858 - val_acc: 0.6336\n",
      "Epoch 196/200\n",
      "47s - loss: 0.0265 - acc: 0.9890 - val_loss: 2.8557 - val_acc: 0.6299\n",
      "Epoch 197/200\n",
      "47s - loss: 0.0249 - acc: 0.9912 - val_loss: 2.6812 - val_acc: 0.6239\n",
      "Epoch 198/200\n",
      "47s - loss: 0.0221 - acc: 0.9913 - val_loss: 2.9782 - val_acc: 0.6269\n",
      "Epoch 199/200\n",
      "47s - loss: 0.0280 - acc: 0.9892 - val_loss: 2.6682 - val_acc: 0.6366\n",
      "Epoch 200/200\n",
      "47s - loss: 0.0262 - acc: 0.9898 - val_loss: 2.9707 - val_acc: 0.6415\n",
      "elapsed secs: 9.458678702116012\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "nb_epoch = 200\n",
    "batch_size=50\n",
    "\n",
    "model_name='test.chkpt'\n",
    "\n",
    "if os.path.isfile(model_name):\n",
    "    try:\n",
    "        model = load_model(model_name)\n",
    "        print('loading trained model ...')\n",
    "    except Exception as e:\n",
    "        print('Unable to load model', model_name, ':', e)\n",
    "        raise    \n",
    "\n",
    "\n",
    "adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(optimizer=adam,\n",
    "          loss='categorical_crossentropy',\n",
    "          metrics=['accuracy'])\n",
    "\n",
    "startTime = time.time()\n",
    "history = model.fit(X_train1, y_train1,\n",
    "                    batch_size=batch_size, epochs=nb_epoch,\n",
    "                    verbose=2, validation_data=(X_test1, y_test1))\n",
    "\n",
    "endTime = time.time()\n",
    "print('elapsed secs:', (endTime - startTime)/1000.)\n",
    "#nvidia-smi to see power stats nvidia-smi -i 3 -l -q -d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv2D)               (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "relu1 (Activation)           (None, 224, 224, 32)      0         \n",
      "_________________________________________________________________\n",
      "maxpool1 (MaxPooling2D)      (None, 223, 223, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 223, 223, 64)      18496     \n",
      "_________________________________________________________________\n",
      "relu2 (Activation)           (None, 223, 223, 64)      0         \n",
      "_________________________________________________________________\n",
      "maxpool2 (MaxPooling2D)      (None, 111, 111, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 111, 111, 128)     73856     \n",
      "_________________________________________________________________\n",
      "relu3 (Activation)           (None, 111, 111, 128)     0         \n",
      "_________________________________________________________________\n",
      "maxpool3 (MaxPooling2D)      (None, 55, 55, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 387200)            0         \n",
      "_________________________________________________________________\n",
      "dropout1 (Dropout)           (None, 387200)            0         \n",
      "_________________________________________________________________\n",
      "hidden1 (Dense)              (None, 128)               49561728  \n",
      "_________________________________________________________________\n",
      "relu4 (Activation)           (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout2 (Dropout)           (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "relu5 (Activation)           (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 3)                 387       \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 49,671,875\n",
      "Trainable params: 49,671,875\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this doesnt work to reset\n",
    "from keras import backend as K\n",
    "\n",
    "def limit_mem():\n",
    "    K.get_session().close()\n",
    "    cfg = K.tf.ConfigProto()\n",
    "    cfg.gpu_options.allow_growth = True\n",
    "    K.set_session(K.tf.Session(config=cfg))\n",
    "\n",
    "limit_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "predict = loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.00749046e-13,   1.00000000e+00,   2.02010197e-11], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
