{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.ndimage as ndi\n",
    "\n",
    "#crop test\n",
    "img = cv2.imread('/Users/dc/DeepLearning/kaggle/train/Type_1/0.jpg')\n",
    "\n",
    "height = img.shape[0]\n",
    "width = img.shape[1]\n",
    "cv2.line(img,(0,int(height/2.)),(int(width),int(height/2.0)),(255,0,0))\n",
    "cv2.line(img,(int(width/2.),0),(int(width/2.0),height),(255,0,0))\n",
    "\n",
    "trans_factor=.8 \n",
    "zoom_range=[.8,.8]\n",
    "\n",
    "\n",
    "y_offset = np.random.uniform(0,trans_factor*width)\n",
    "x_offset = np.random.uniform(0,trans_factor*height)\n",
    "\n",
    "print ('y_offset:', y_offset, \"x_offset:\", x_offset)\n",
    "\n",
    "offset = np.array([0,200])\n",
    "#center image\n",
    "#offset=np.array([10,10])\n",
    "scale_factor = np.random.uniform(zoom_range[0],zoom_range[1])\n",
    "print (scale_factor)\n",
    "crop = np.array([[scale_factor,0],[0,scale_factor]])\n",
    "\n",
    "print('image.shape before roll:',img.shape)\n",
    "img_roll = np.rollaxis(img,axis=-1, start=0)\n",
    "print('image.shape after roll:',img_roll.shape)\n",
    "#this is for the affine transform for each channel you have to roll the axis? Seems funky\n",
    "#you can use a numpy.reshape also. this is clearer and more mainstream\n",
    "\n",
    "image_channel = [ndi.interpolation.affine_transform(image_channel,\n",
    "                        crop, offset=offset, order=0, mode='nearest',\n",
    "                        cval=0.0) for image_channel in img_roll]\n",
    "image_array = np.stack(image_channel, axis=0)\n",
    "image_array = np.rollaxis(image_array, 0, 3)\n",
    "\n",
    "print ('image_array:',image_array.shape)\n",
    "#height_rs = image_array.shape[0]\n",
    "#width_rs = image_array.shape[1]\n",
    "#print(height_rs, width_rs)\n",
    "#cv2.line(image_array,(10,10),(100,100),(255,0,0))\n",
    "#cv2.line(image_array,(0,int(height_rs/2.)),(int(width_rs),int(height_rs/2.0)),(255,0,0))\n",
    "#cv2.line(image_array,(int(width_rs/2.),0),(int(width_rs/2.0),height_rs),(255,0,0))\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 1)\n",
    "ax.imshow(img)\n",
    "plt.title(\"orig\")\n",
    "ax1 = fig.add_subplot(2, 2, 2)\n",
    "ax1.imshow(image_array)\n",
    "plt.title(\"crop .8\")\n",
    "#fig.add_subplot(image_array)\n",
    "\n",
    "#plt.show()\n",
    "#problem is the shift away from center in the crop .8 image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#we can crop to produce a smaller resolution. \n",
    "import skimage\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "\n",
    "image = cv2.imread('/Users/dc/DeepLearning/kaggle/train/Type_1/0.jpg')\n",
    "height = image.shape[0]\n",
    "width = image.shape[1]\n",
    "cv2.line(image,(0,int(height/2.)),(int(width),int(height/2.0)),(255,0,0))\n",
    "cv2.line(image,(int(width/2.),0),(int(width/2.0),height),(255,0,0))\n",
    "\n",
    "\n",
    "print ('orig:',image.shape)\n",
    "image_resized = resize(image, (400, 400), mode='reflect')\n",
    "height = image_resized.shape[0]\n",
    "width = image_resized.shape[1]\n",
    "cv2.line(image_resized,(0,int(height/2.)),(int(width),int(height/2.0)),(255,0,0))\n",
    "cv2.line(image_resized,(int(width/2.),0),(int(width/2.0),height),(255,0,0))\n",
    "\n",
    "#image_downscaled = downscale_local_mean(image, (480, 640))\n",
    "print ('resized:',image_resized.shape)\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2,\n",
    "                         sharex=True, sharey=True)\n",
    "\n",
    "ax = axes.ravel()\n",
    "ax[0].imshow(image)\n",
    "ax[0].set_title(\"Original image\")\n",
    "\n",
    "ax[1].imshow(image_resized)\n",
    "ax[1].set_title(\"resized\")\n",
    "\n",
    "#ax[2].imshow(image_downscaled)\n",
    "#ax[2].set_title(\"downscaled\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#not used\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(img1,lab_1, test_size=.20, random_state=42)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(img2,lab_2,test_size=.20, random_state=42)\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(img3,lab_3,test_size=.20, random_state=42)\n",
    "\n",
    "X_train1 = np.array(X_train1)\n",
    "X_test1 = np.array(X_test1)\n",
    "print(type(X_train1), type(X_test1), type(y_train1), type(y_test1))\n",
    "\n",
    "X_train2 = np.array(X_train2)\n",
    "X_test2 = np.array(X_test2)\n",
    "\n",
    "X_train3 = np.array(X_train3)\n",
    "X_test3 = np.array(X_test3)\n",
    "\n",
    "\n",
    "print(X_train1.shape, X_test1.shape, y_train1.shape, y_test1.shape)\n",
    "print(X_train2.shape, X_test2.shape, y_train2.shape, y_test2.shape)\n",
    "print(X_train3.shape, X_test3.shape, y_train3.shape, y_test3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#not used\n",
    "X_train = np.concatenate((X_train1,X_train2,X_train3))\n",
    "X_test = np.concatenate((X_test1, X_test2, X_test3))\n",
    "y_train = np.concatenate((y_train1, y_train2, y_train3))\n",
    "y_test = np.concatenate((y_test1, y_test2, y_test3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "lab_1 = np_utils.to_categorical(label_1, 3)\n",
    "lab_2 = np_utils.to_categorical(label_2, 3)\n",
    "lab_3 = np_utils.to_categorical(label_3, 3)\n",
    "\n",
    "img_1 = np.array(img1)\n",
    "img_2 = np.array(img2)\n",
    "img_3 = np.array(img3)\n",
    "\n",
    "print (img_1.shape,lab_1.shape)\n",
    "print (img_2.shape,lab_2.shape)\n",
    "print (img_3.shape,lab_3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
