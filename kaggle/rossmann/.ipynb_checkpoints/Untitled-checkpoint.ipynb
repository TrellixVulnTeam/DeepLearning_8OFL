{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "https://github.com/fchollet/keras/issues/3110\n",
    "embedding word2vec example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_word2vec_model(num_ns, embedding_dim, num_words, separate_context = True):\n",
    "\t'''\n",
    "\tnum_ns: (int) number of negative samples\n",
    "\tembedding_dim: (int) embedding dimension\n",
    "\tnum_words: (int) size of the vocabulary\n",
    "\tseparate_context: (bool) whether or not to use a separate set of word embeddings\n",
    "\t\t\t\t\t\t\tfor the context embeddings. Reccomended for text data to\n",
    "\t\t\t\t\t\t\tbetter fit the distributional hypothesis.\n",
    "\n",
    "\tcreates a skipgram with negative sampling model. word_input is a (batch_size, 1)\n",
    "\tshaped tensor indicating the index of the center word in the sliding window. context_input\n",
    "\tis a (batch_size, num_ns+1) shaped tensor, where the first column are the indices\n",
    "\tof the positive samples, and the num_ns following columns are the indices of the negative\n",
    "\tsamples. Labels should be a (batch_size, num_ns+1) shaped tensor, where the first column\n",
    "\tis ones (positive label) and the rest of the matrix is zero (negative label)\n",
    "\t'''\n",
    "\tfrom keras.layers import Input, Embedding, Reshape, Merge, Flatten, Activation\n",
    "\tfrom keras.models import Model\n",
    "\n",
    "\tword_input = Input(shape = (1,), dtype = 'int32')\n",
    "\tcontext_input = Input(shape = (num_ns+1,), dtype = 'int32')\n",
    "\n",
    "\tnode_embedding = Embedding(num_nodes, embedding_dim)\n",
    "\twe = node_embedding(word_input)\n",
    "\n",
    "\tif separate_context:\n",
    "\t\tcontext_embedding = Embedding(num_nodes, embedding_dim)\n",
    "\telse:\n",
    "\t\tcontext_embedding = node_embedding\n",
    "\tce = Reshape((embedding_dim,num_ns+1))(context_embedding(context_input))\n",
    "\n",
    "\tdots = Flatten()(Merge(mode = 'dot', dot_axes = (1,2))([ce, we]))\n",
    "\tacts = Activation('sigmoid')(dots)\n",
    "\t\n",
    "\tmodel = Model(input = [word_input, context_input], output = acts)\n",
    "\tmodel.compile('adam', loss = 'binary_crossentropy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
